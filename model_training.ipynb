{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score  \n",
    "from sklearn.metrics import recall_score, f1_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('/home/saif/Desktop/Customer Churn Analysis and Prediction/top_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7010 entries, 0 to 7009\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   TotalCharges      7010 non-null   float64\n",
      " 1   MonthlyCharges    7010 non-null   float64\n",
      " 2   tenure            7010 non-null   int64  \n",
      " 3   Contract          7010 non-null   int64  \n",
      " 4   PaymentMethod     7010 non-null   int64  \n",
      " 5   InternetService   7010 non-null   int64  \n",
      " 6   OnlineBackup      7010 non-null   int64  \n",
      " 7   OnlineSecurity    7010 non-null   int64  \n",
      " 8   gender            7010 non-null   int64  \n",
      " 9   TechSupport       7010 non-null   int64  \n",
      " 10  PaperlessBilling  7010 non-null   int64  \n",
      " 11  MultipleLines     7010 non-null   int64  \n",
      " 12  Churn             7010 non-null   int64  \n",
      "dtypes: float64(2), int64(11)\n",
      "memory usage: 712.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>tenure</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>gender</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7010.000000</td>\n",
       "      <td>7010.000000</td>\n",
       "      <td>7010.000000</td>\n",
       "      <td>7010.000000</td>\n",
       "      <td>7010.000000</td>\n",
       "      <td>7010.000000</td>\n",
       "      <td>7010.000000</td>\n",
       "      <td>7010.000000</td>\n",
       "      <td>7010.000000</td>\n",
       "      <td>7010.000000</td>\n",
       "      <td>7010.000000</td>\n",
       "      <td>7010.000000</td>\n",
       "      <td>7010.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2290.353388</td>\n",
       "      <td>64.888666</td>\n",
       "      <td>32.520399</td>\n",
       "      <td>8.838374</td>\n",
       "      <td>2.317404</td>\n",
       "      <td>1.225963</td>\n",
       "      <td>0.131098</td>\n",
       "      <td>0.072611</td>\n",
       "      <td>0.504280</td>\n",
       "      <td>0.076177</td>\n",
       "      <td>0.593153</td>\n",
       "      <td>0.326248</td>\n",
       "      <td>0.264907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2266.820832</td>\n",
       "      <td>30.064769</td>\n",
       "      <td>24.520441</td>\n",
       "      <td>9.546590</td>\n",
       "      <td>1.150581</td>\n",
       "      <td>0.777600</td>\n",
       "      <td>0.737334</td>\n",
       "      <td>0.705040</td>\n",
       "      <td>0.500017</td>\n",
       "      <td>0.707190</td>\n",
       "      <td>0.491281</td>\n",
       "      <td>0.643333</td>\n",
       "      <td>0.441315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.800000</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>408.312500</td>\n",
       "      <td>35.750000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1403.875000</td>\n",
       "      <td>70.400000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3807.837500</td>\n",
       "      <td>89.900000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8684.800000</td>\n",
       "      <td>118.750000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TotalCharges  MonthlyCharges       tenure     Contract  PaymentMethod  \\\n",
       "count   7010.000000     7010.000000  7010.000000  7010.000000    7010.000000   \n",
       "mean    2290.353388       64.888666    32.520399     8.838374       2.317404   \n",
       "std     2266.820832       30.064769    24.520441     9.546590       1.150581   \n",
       "min       18.800000       18.250000     1.000000     1.000000       1.000000   \n",
       "25%      408.312500       35.750000     9.000000     1.000000       1.000000   \n",
       "50%     1403.875000       70.400000    29.000000     1.000000       2.000000   \n",
       "75%     3807.837500       89.900000    56.000000    12.000000       3.000000   \n",
       "max     8684.800000      118.750000    72.000000    24.000000       4.000000   \n",
       "\n",
       "       InternetService  OnlineBackup  OnlineSecurity       gender  \\\n",
       "count      7010.000000   7010.000000     7010.000000  7010.000000   \n",
       "mean          1.225963      0.131098        0.072611     0.504280   \n",
       "std           0.777600      0.737334        0.705040     0.500017   \n",
       "min           0.000000     -1.000000       -1.000000     0.000000   \n",
       "25%           1.000000      0.000000        0.000000     0.000000   \n",
       "50%           1.000000      0.000000        0.000000     1.000000   \n",
       "75%           2.000000      1.000000        1.000000     1.000000   \n",
       "max           2.000000      1.000000        1.000000     1.000000   \n",
       "\n",
       "       TechSupport  PaperlessBilling  MultipleLines        Churn  \n",
       "count  7010.000000       7010.000000    7010.000000  7010.000000  \n",
       "mean      0.076177          0.593153       0.326248     0.264907  \n",
       "std       0.707190          0.491281       0.643333     0.441315  \n",
       "min      -1.000000          0.000000      -1.000000     0.000000  \n",
       "25%       0.000000          0.000000       0.000000     0.000000  \n",
       "50%       0.000000          1.000000       0.000000     0.000000  \n",
       "75%       1.000000          1.000000       1.000000     1.000000  \n",
       "max       1.000000          1.000000       1.000000     1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TotalCharges', 'MonthlyCharges', 'tenure', 'Contract', 'PaymentMethod',\n",
       "       'InternetService', 'OnlineBackup', 'OnlineSecurity', 'gender',\n",
       "       'TechSupport', 'PaperlessBilling', 'MultipleLines', 'Churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>tenure</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>gender</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>185.40</td>\n",
       "      <td>20.00</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>947.75</td>\n",
       "      <td>25.25</td>\n",
       "      <td>39</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>6590.50</td>\n",
       "      <td>104.05</td>\n",
       "      <td>62</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>775.30</td>\n",
       "      <td>75.20</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4051</th>\n",
       "      <td>5515.80</td>\n",
       "      <td>79.60</td>\n",
       "      <td>68</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TotalCharges  MonthlyCharges  tenure  Contract  PaymentMethod  \\\n",
       "2766        185.40           20.00      10         1              1   \n",
       "1684        947.75           25.25      39        12              4   \n",
       "4169       6590.50          104.05      62        24              1   \n",
       "1137        775.30           75.20      11         1              4   \n",
       "4051       5515.80           79.60      68        24              3   \n",
       "\n",
       "      InternetService  OnlineBackup  OnlineSecurity  gender  TechSupport  \\\n",
       "2766                0            -1              -1       1           -1   \n",
       "1684                1             0               0       1            0   \n",
       "4169                2             0               0       1            1   \n",
       "1137                2             0               0       1            0   \n",
       "4051                1             1               1       0            1   \n",
       "\n",
       "      PaperlessBilling  MultipleLines  Churn  \n",
       "2766                 0              0      0  \n",
       "1684                 1             -1      0  \n",
       "4169                 1              1      0  \n",
       "1137                 1              1      0  \n",
       "4051                 1              0      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying min max scaling on TotalCharges, MonthlyCharges,tenure, and Contract columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply min max scaling on TotalCharges, MonthlyCharges, and tenure\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df['TotalCharges'] = scaler.fit_transform(df[['TotalCharges']])\n",
    "df['MonthlyCharges'] = scaler.fit_transform(df[['MonthlyCharges']])\n",
    "df['tenure'] = scaler.fit_transform(df[['tenure']])\n",
    "df['Contract'] = scaler.fit_transform(df[['Contract']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>tenure</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>gender</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6362</th>\n",
       "      <td>0.700958</td>\n",
       "      <td>0.649751</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3351</th>\n",
       "      <td>0.039159</td>\n",
       "      <td>0.013930</td>\n",
       "      <td>0.253521</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.135460</td>\n",
       "      <td>0.010448</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0.215492</td>\n",
       "      <td>0.704478</td>\n",
       "      <td>0.295775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>0.128375</td>\n",
       "      <td>0.117910</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TotalCharges  MonthlyCharges    tenure  Contract  PaymentMethod  \\\n",
       "6362      0.700958        0.649751  1.000000       1.0              4   \n",
       "3351      0.039159        0.013930  0.253521       1.0              2   \n",
       "194       0.135460        0.010448  0.816901       1.0              4   \n",
       "311       0.215492        0.704478  0.295775       0.0              1   \n",
       "2600      0.128375        0.117910  0.535211       0.0              4   \n",
       "\n",
       "      InternetService  OnlineBackup  OnlineSecurity  gender  TechSupport  \\\n",
       "6362                1             0               1       1            1   \n",
       "3351                0            -1              -1       1           -1   \n",
       "194                 0            -1              -1       1           -1   \n",
       "311                 2             0               1       0            1   \n",
       "2600                1             0               0       0            0   \n",
       "\n",
       "      PaperlessBilling  MultipleLines  Churn  \n",
       "6362                 1              1      0  \n",
       "3351                 0              0      0  \n",
       "194                  0              0      0  \n",
       "311                  1              0      0  \n",
       "2600                 0             -1      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 : Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5608, 12), (1402, 12), (5608,), (1402,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 : Model Selection\n",
    "I will train these model in order from 1 to 7 \n",
    "\n",
    "**1.Logistic Regression (Baseline Model)**\n",
    "\n",
    "**2.Decision Tree Classifier**\n",
    "\n",
    "**3.Random Forest Classifier**\n",
    "\n",
    "**4.XGBoost**\n",
    "\n",
    "**5.LightGBM**\n",
    "\n",
    "**6.CatBoost**\n",
    "\n",
    "**7.Support Vector Machine (SVM)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training logistic regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "y_pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8259629101283881\n",
      "Precision: 0.6410256410256411\n",
      "Recall: 0.5451713395638629\n",
      "F1-score: 0.5892255892255891\n",
      "ROC-AUC: 0.7272572701519592\n"
     ]
    }
   ],
   "source": [
    "# evaluate model accuracy,precision, recall, F1-score, and ROC-AUC.\n",
    "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "lr_precision = precision_score(y_test, y_pred_lr)\n",
    "lr_recall = recall_score(y_test, y_pred_lr)\n",
    "lr_f1 = f1_score(y_test, y_pred_lr)\n",
    "lr_roc_auc = roc_auc_score(y_test, y_pred_lr)\n",
    "print('Accuracy:', lr_accuracy)\n",
    "print('Precision:', lr_precision)\n",
    "print('Recall:', lr_recall)\n",
    "print('F1-score:', lr_f1)\n",
    "print('ROC-AUC:', lr_roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.Accuracy (82.6%)** → The model is mostly correct, but that doesn’t mean it’s perfect.\n",
    "\n",
    "**2.Precision (64.1%)** → When the model predicts a customer will leave, it’s right 64% of the time.\n",
    "\n",
    "**3.Recall (54.5%)** → The model is missing almost **half** of the actual churners, which is a problem if you want to save them.\n",
    "\n",
    "**4.F1-Score (58.9%)** → A balance between catching churners and being correct when predicting churn. Not great, but not terrible.\n",
    "\n",
    "**5.ROC-AUC (72.7%)** → The model is better than random guessing but needs improvement.\n",
    "\n",
    "**Key Takeaway:**\n",
    "- it fails to catch **many real churners**. The goal is to stop customers from leaving,so  model should improve recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Decision Tree Classifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on test data\n",
    "y_pred_dt = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7425106990014265\n",
      "Precision: 0.4470899470899471\n",
      "Recall: 0.5264797507788161\n",
      "F1-score: 0.4835479256080114\n",
      "ROC-AUC: 0.6665701251581407\n"
     ]
    }
   ],
   "source": [
    "# evaluate model accuracy,precision, recall, F1-score, and ROC-AUC.\n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "dt_precision = precision_score(y_test, y_pred_dt)\n",
    "dt_recall = recall_score(y_test, y_pred_dt)\n",
    "dt_f1 = f1_score(y_test, y_pred_dt)\n",
    "dt_roc_auc = roc_auc_score(y_test, y_pred_dt)\n",
    "print('Accuracy:', dt_accuracy)\n",
    "print('Precision:', dt_precision)\n",
    "print('Recall:', dt_recall)\n",
    "print('F1-score:', dt_f1)\n",
    "print('ROC-AUC:', dt_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression model is better than the Decision Tree in almost every way**. Here's why:\n",
    "\n",
    "**1.Logistic Regression is more accurate (82.6% vs. 74.3%)**, meaning it makes fewer mistakes overall.\n",
    "\n",
    "**2.It gives better precision (64.1% vs. 44.7%)**, so when it predicts a customer will leave, it's right more often.\n",
    "\n",
    "**3.Both models have similar recall (~54% vs. ~52%)**, meaning they catch about the same number of actual churners.\n",
    "\n",
    "**4.Logistic Regression has a better balance (F1-score 58.9% vs. 48.4%)**, so it’s more reliable.\n",
    "\n",
    "**5.It also does a better job of separating churners from non-churners (ROC-AUC 72.7% vs. 66.7%)**.\n",
    "\n",
    "#### What This Means\n",
    "Logistic Regression is the better model right now because it makes fewer mistakes and is more reliable.\n",
    "\n",
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Random Forest Classifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction on test data\n",
    "y_pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8045649072753209\n",
      "Precision: 0.5824561403508772\n",
      "Recall: 0.5171339563862928\n",
      "F1-score: 0.5478547854785478\n",
      "ROC-AUC: 0.7035253500710371\n"
     ]
    }
   ],
   "source": [
    "# evaluate model accuracy,precision, recall, F1-score, and ROC-AUC.\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "rf_precision = precision_score(y_test, y_pred_rf)\n",
    "rf_recall = recall_score(y_test, y_pred_rf)\n",
    "rf_f1 = f1_score(y_test, y_pred_rf)\n",
    "rf_roc_auc = roc_auc_score(y_test, y_pred_rf)\n",
    "print('Accuracy:', rf_accuracy)\n",
    "print('Precision:', rf_precision)\n",
    "print('Recall:', rf_recall)\n",
    "print('F1-score:', rf_f1)\n",
    "print('ROC-AUC:', rf_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest model is better than Decision Tree but still worse than Logistic Regression in some areas. Here’s a simple breakdown:\n",
    "\n",
    "**1.Accuracy (80.5%)** → Better than Decision Tree (74.3%) but still lower than Logistic Regression (82.6%).\n",
    "\n",
    "**2.Precision (58.2%)** → Better than Decision Tree (44.7%) but lower than Logistic Regression (64.1%).\n",
    "\n",
    "**3.Recall (51.7%)** → Almost the same as before, meaning it’s catching about the same number of churners as Logistic Regression (~54.5%).\n",
    "\n",
    "**4.F1-score (54.8%)** → Better than Decision Tree (48.4%) but still lower than Logistic Regression (58.9%).\n",
    "\n",
    "**5.ROC-AUC (70.4%)** → Improved from Decision Tree (66.7%) but still lower than Logistic Regression (72.7%).\n",
    "\n",
    "#### What This Means:\n",
    "\n",
    "- Random Forest is a step up from Decision Tree but not as strong as Logistic Regression in this case.\n",
    "- Precision dropped compared to Logistic Regression, meaning it’s making more false positive mistakes.\n",
    "\n",
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training XGBoost Classifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on test data\n",
    "y_pred_xgb = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8074179743223966\n",
      "Precision: 0.580952380952381\n",
      "Recall: 0.5700934579439252\n",
      "F1-score: 0.5754716981132076\n",
      "ROC-AUC: 0.7239921498785306\n"
     ]
    }
   ],
   "source": [
    "# evaluate model accuracy,precision, recall, F1-score, and ROC-AUC.\n",
    "xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "xgb_precision = precision_score(y_test, y_pred_xgb)\n",
    "xgb_recall = recall_score(y_test, y_pred_xgb)\n",
    "xgb_f1 = f1_score(y_test, y_pred_xgb)\n",
    "xgb_roc_auc = roc_auc_score(y_test, y_pred_xgb)\n",
    "print('Accuracy:', xgb_accuracy)\n",
    "print('Precision:', xgb_precision)\n",
    "print('Recall:', xgb_recall)\n",
    "print('F1-score:', xgb_f1)\n",
    "print('ROC-AUC:', xgb_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost model is now performing better than Random Forest and Decision Tree, and it's almost as good as Logistic Regression! Here's a simple breakdown:\n",
    "\n",
    "**1.Accuracy (80.7%)** → Slightly better than Random Forest (80.5%) but still lower than Logistic Regression (82.6%).\n",
    "\n",
    "**2.Precision (58.1%)** → Similar to Random Forest (58.2%) but lower than Logistic Regression (64.1%).\n",
    "\n",
    "**3.Recall (57.0%)** → Best recall so far! Better than Logistic Regression (54.5%) and Random Forest (51.7%).\n",
    "\n",
    "**4.F1-score (57.5%)** → Higher than Random Forest (54.8%), but slightly lower than Logistic Regression (58.9%).\n",
    "\n",
    "**5.ROC-AUC (72.4%)** → Almost equal to Logistic Regression (72.7%), meaning XGBoost is just as good at separating churners from non-churners.\n",
    "\n",
    "#### What This Means:\n",
    "\n",
    "- XGBoost is the best at catching churners (highest recall so far).\n",
    "- It performs close to Logistic Regression overall.\n",
    "\n",
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1536, number of negative: 4072\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 5608, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.273894 -> initscore=-0.974953\n",
      "[LightGBM] [Info] Start training from score -0.974953\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training lightGBM Classifier\n",
    "lgb = lgb.LGBMClassifier()\n",
    "lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on test data\n",
    "y_pred_lgb = lgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8102710413694721\n",
      "Precision: 0.5925925925925926\n",
      "Recall: 0.5482866043613707\n",
      "F1-score: 0.5695792880258899\n",
      "ROC-AUC: 0.7181766046783727\n"
     ]
    }
   ],
   "source": [
    "# evaluate model accuracy,precision, recall, F1-score, and ROC-AUC.\n",
    "lgb_accuracy = accuracy_score(y_test, y_pred_lgb)\n",
    "lgb_precision = precision_score(y_test, y_pred_lgb)\n",
    "lgb_recall = recall_score(y_test, y_pred_lgb)\n",
    "lgb_f1 = f1_score(y_test, y_pred_lgb)\n",
    "lgb_roc_auc = roc_auc_score(y_test, y_pred_lgb)\n",
    "print('Accuracy:', lgb_accuracy)\n",
    "print('Precision:', lgb_precision)\n",
    "print('Recall:', lgb_recall)\n",
    "print('F1-score:', lgb_f1)\n",
    "print('ROC-AUC:', lgb_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM model is performing slightly better than XGBoost in some areas but not in others. Here’s a simple comparison:\n",
    "\n",
    "**1.Accuracy (81.0%)** → Slightly better than XGBoost (80.7%) but still lower than Logistic Regression (82.6%).\n",
    "\n",
    "**2.Precision (59.3%)** → Better than XGBoost (58.1%) but still lower than Logistic Regression (64.1%).\n",
    "\n",
    "**3.Recall (54.8%)** → Lower than XGBoost (57.0%) but similar to Logistic Regression (54.5%).\n",
    "\n",
    "**4.F1-score (56.9%)** → Almost the same as XGBoost (57.5%), meaning both balance precision and recall well.\n",
    "\n",
    "**5.ROC-AUC (71.8%)** → Slightly worse than XGBoost (72.4%) and Logistic Regression (72.7%), meaning it’s not the best at separating churners from non-churners.\n",
    "\n",
    "#### What This Means:\n",
    "\n",
    "- LightGBM and XGBoost are very close in performance.\n",
    "- XGBoost is better at catching churners (higher recall).\n",
    "- LightGBM is slightly more accurate and has better precision.\n",
    "- Neither has beaten Logistic Regression yet.\n",
    "\n",
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.021512\n",
      "0:\tlearn: 0.6776523\ttotal: 59.1ms\tremaining: 59.1s\n",
      "1:\tlearn: 0.6633492\ttotal: 70.1ms\tremaining: 35s\n",
      "2:\tlearn: 0.6507619\ttotal: 73.1ms\tremaining: 24.3s\n",
      "3:\tlearn: 0.6381747\ttotal: 76.8ms\tremaining: 19.1s\n",
      "4:\tlearn: 0.6271026\ttotal: 86.5ms\tremaining: 17.2s\n",
      "5:\tlearn: 0.6162299\ttotal: 89.5ms\tremaining: 14.8s\n",
      "6:\tlearn: 0.6060567\ttotal: 93ms\tremaining: 13.2s\n",
      "7:\tlearn: 0.5964787\ttotal: 96.5ms\tremaining: 12s\n",
      "8:\tlearn: 0.5866813\ttotal: 100ms\tremaining: 11s\n",
      "9:\tlearn: 0.5781369\ttotal: 103ms\tremaining: 10.2s\n",
      "10:\tlearn: 0.5700041\ttotal: 107ms\tremaining: 9.6s\n",
      "11:\tlearn: 0.5621540\ttotal: 123ms\tremaining: 10.1s\n",
      "12:\tlearn: 0.5555346\ttotal: 125ms\tremaining: 9.5s\n",
      "13:\tlearn: 0.5486267\ttotal: 132ms\tremaining: 9.27s\n",
      "14:\tlearn: 0.5418331\ttotal: 135ms\tremaining: 8.84s\n",
      "15:\tlearn: 0.5357530\ttotal: 138ms\tremaining: 8.48s\n",
      "16:\tlearn: 0.5309288\ttotal: 141ms\tremaining: 8.13s\n",
      "17:\tlearn: 0.5251962\ttotal: 146ms\tremaining: 7.95s\n",
      "18:\tlearn: 0.5199429\ttotal: 156ms\tremaining: 8.07s\n",
      "19:\tlearn: 0.5158357\ttotal: 161ms\tremaining: 7.91s\n",
      "20:\tlearn: 0.5114683\ttotal: 164ms\tremaining: 7.64s\n",
      "21:\tlearn: 0.5071042\ttotal: 167ms\tremaining: 7.44s\n",
      "22:\tlearn: 0.5026944\ttotal: 170ms\tremaining: 7.22s\n",
      "23:\tlearn: 0.4985301\ttotal: 173ms\tremaining: 7.03s\n",
      "24:\tlearn: 0.4947493\ttotal: 176ms\tremaining: 6.85s\n",
      "25:\tlearn: 0.4914203\ttotal: 179ms\tremaining: 6.71s\n",
      "26:\tlearn: 0.4883694\ttotal: 182ms\tremaining: 6.57s\n",
      "27:\tlearn: 0.4848958\ttotal: 185ms\tremaining: 6.44s\n",
      "28:\tlearn: 0.4824877\ttotal: 188ms\tremaining: 6.29s\n",
      "29:\tlearn: 0.4794438\ttotal: 192ms\tremaining: 6.22s\n",
      "30:\tlearn: 0.4766109\ttotal: 196ms\tremaining: 6.13s\n",
      "31:\tlearn: 0.4735873\ttotal: 199ms\tremaining: 6.01s\n",
      "32:\tlearn: 0.4710316\ttotal: 201ms\tremaining: 5.89s\n",
      "33:\tlearn: 0.4687033\ttotal: 203ms\tremaining: 5.77s\n",
      "34:\tlearn: 0.4665966\ttotal: 206ms\tremaining: 5.68s\n",
      "35:\tlearn: 0.4644855\ttotal: 209ms\tremaining: 5.6s\n",
      "36:\tlearn: 0.4624951\ttotal: 213ms\tremaining: 5.54s\n",
      "37:\tlearn: 0.4604046\ttotal: 216ms\tremaining: 5.47s\n",
      "38:\tlearn: 0.4585228\ttotal: 219ms\tremaining: 5.4s\n",
      "39:\tlearn: 0.4569108\ttotal: 221ms\tremaining: 5.31s\n",
      "40:\tlearn: 0.4555577\ttotal: 224ms\tremaining: 5.23s\n",
      "41:\tlearn: 0.4539684\ttotal: 227ms\tremaining: 5.17s\n",
      "42:\tlearn: 0.4524631\ttotal: 231ms\tremaining: 5.14s\n",
      "43:\tlearn: 0.4509094\ttotal: 234ms\tremaining: 5.09s\n",
      "44:\tlearn: 0.4492962\ttotal: 238ms\tremaining: 5.04s\n",
      "45:\tlearn: 0.4478600\ttotal: 241ms\tremaining: 5s\n",
      "46:\tlearn: 0.4465955\ttotal: 245ms\tremaining: 4.97s\n",
      "47:\tlearn: 0.4453416\ttotal: 249ms\tremaining: 4.94s\n",
      "48:\tlearn: 0.4444847\ttotal: 253ms\tremaining: 4.91s\n",
      "49:\tlearn: 0.4432354\ttotal: 258ms\tremaining: 4.89s\n",
      "50:\tlearn: 0.4420940\ttotal: 265ms\tremaining: 4.93s\n",
      "51:\tlearn: 0.4409886\ttotal: 272ms\tremaining: 4.96s\n",
      "52:\tlearn: 0.4398951\ttotal: 276ms\tremaining: 4.93s\n",
      "53:\tlearn: 0.4388059\ttotal: 279ms\tremaining: 4.89s\n",
      "54:\tlearn: 0.4377771\ttotal: 283ms\tremaining: 4.86s\n",
      "55:\tlearn: 0.4367642\ttotal: 287ms\tremaining: 4.83s\n",
      "56:\tlearn: 0.4358264\ttotal: 290ms\tremaining: 4.8s\n",
      "57:\tlearn: 0.4350717\ttotal: 294ms\tremaining: 4.78s\n",
      "58:\tlearn: 0.4342097\ttotal: 298ms\tremaining: 4.75s\n",
      "59:\tlearn: 0.4333143\ttotal: 302ms\tremaining: 4.73s\n",
      "60:\tlearn: 0.4324882\ttotal: 306ms\tremaining: 4.71s\n",
      "61:\tlearn: 0.4316768\ttotal: 311ms\tremaining: 4.71s\n",
      "62:\tlearn: 0.4308878\ttotal: 327ms\tremaining: 4.86s\n",
      "63:\tlearn: 0.4301274\ttotal: 335ms\tremaining: 4.9s\n",
      "64:\tlearn: 0.4294168\ttotal: 345ms\tremaining: 4.96s\n",
      "65:\tlearn: 0.4286791\ttotal: 354ms\tremaining: 5.01s\n",
      "66:\tlearn: 0.4278592\ttotal: 372ms\tremaining: 5.18s\n",
      "67:\tlearn: 0.4270920\ttotal: 383ms\tremaining: 5.25s\n",
      "68:\tlearn: 0.4264515\ttotal: 394ms\tremaining: 5.31s\n",
      "69:\tlearn: 0.4257493\ttotal: 404ms\tremaining: 5.37s\n",
      "70:\tlearn: 0.4251610\ttotal: 410ms\tremaining: 5.36s\n",
      "71:\tlearn: 0.4245296\ttotal: 415ms\tremaining: 5.35s\n",
      "72:\tlearn: 0.4240066\ttotal: 423ms\tremaining: 5.37s\n",
      "73:\tlearn: 0.4235492\ttotal: 433ms\tremaining: 5.42s\n",
      "74:\tlearn: 0.4230052\ttotal: 450ms\tremaining: 5.54s\n",
      "75:\tlearn: 0.4224363\ttotal: 459ms\tremaining: 5.58s\n",
      "76:\tlearn: 0.4219063\ttotal: 463ms\tremaining: 5.55s\n",
      "77:\tlearn: 0.4213691\ttotal: 472ms\tremaining: 5.58s\n",
      "78:\tlearn: 0.4208834\ttotal: 482ms\tremaining: 5.62s\n",
      "79:\tlearn: 0.4204035\ttotal: 491ms\tremaining: 5.64s\n",
      "80:\tlearn: 0.4199456\ttotal: 508ms\tremaining: 5.77s\n",
      "81:\tlearn: 0.4195218\ttotal: 520ms\tremaining: 5.82s\n",
      "82:\tlearn: 0.4190798\ttotal: 528ms\tremaining: 5.83s\n",
      "83:\tlearn: 0.4185835\ttotal: 543ms\tremaining: 5.92s\n",
      "84:\tlearn: 0.4181140\ttotal: 558ms\tremaining: 6s\n",
      "85:\tlearn: 0.4176959\ttotal: 567ms\tremaining: 6.02s\n",
      "86:\tlearn: 0.4173498\ttotal: 574ms\tremaining: 6.02s\n",
      "87:\tlearn: 0.4169600\ttotal: 587ms\tremaining: 6.08s\n",
      "88:\tlearn: 0.4165535\ttotal: 596ms\tremaining: 6.1s\n",
      "89:\tlearn: 0.4161643\ttotal: 609ms\tremaining: 6.16s\n",
      "90:\tlearn: 0.4157859\ttotal: 614ms\tremaining: 6.13s\n",
      "91:\tlearn: 0.4155967\ttotal: 618ms\tremaining: 6.1s\n",
      "92:\tlearn: 0.4154420\ttotal: 621ms\tremaining: 6.06s\n",
      "93:\tlearn: 0.4150648\ttotal: 626ms\tremaining: 6.03s\n",
      "94:\tlearn: 0.4147656\ttotal: 630ms\tremaining: 6s\n",
      "95:\tlearn: 0.4144780\ttotal: 638ms\tremaining: 6.01s\n",
      "96:\tlearn: 0.4141786\ttotal: 643ms\tremaining: 5.99s\n",
      "97:\tlearn: 0.4138369\ttotal: 649ms\tremaining: 5.97s\n",
      "98:\tlearn: 0.4135426\ttotal: 656ms\tremaining: 5.97s\n",
      "99:\tlearn: 0.4132502\ttotal: 684ms\tremaining: 6.15s\n",
      "100:\tlearn: 0.4130347\ttotal: 694ms\tremaining: 6.17s\n",
      "101:\tlearn: 0.4127275\ttotal: 704ms\tremaining: 6.2s\n",
      "102:\tlearn: 0.4124539\ttotal: 713ms\tremaining: 6.21s\n",
      "103:\tlearn: 0.4121294\ttotal: 719ms\tremaining: 6.19s\n",
      "104:\tlearn: 0.4117009\ttotal: 726ms\tremaining: 6.19s\n",
      "105:\tlearn: 0.4113658\ttotal: 741ms\tremaining: 6.25s\n",
      "106:\tlearn: 0.4111144\ttotal: 746ms\tremaining: 6.22s\n",
      "107:\tlearn: 0.4107599\ttotal: 752ms\tremaining: 6.21s\n",
      "108:\tlearn: 0.4104299\ttotal: 766ms\tremaining: 6.26s\n",
      "109:\tlearn: 0.4100668\ttotal: 779ms\tremaining: 6.3s\n",
      "110:\tlearn: 0.4099127\ttotal: 788ms\tremaining: 6.31s\n",
      "111:\tlearn: 0.4095238\ttotal: 796ms\tremaining: 6.31s\n",
      "112:\tlearn: 0.4092981\ttotal: 813ms\tremaining: 6.38s\n",
      "113:\tlearn: 0.4090576\ttotal: 817ms\tremaining: 6.35s\n",
      "114:\tlearn: 0.4087710\ttotal: 820ms\tremaining: 6.31s\n",
      "115:\tlearn: 0.4085758\ttotal: 824ms\tremaining: 6.28s\n",
      "116:\tlearn: 0.4083124\ttotal: 829ms\tremaining: 6.25s\n",
      "117:\tlearn: 0.4079765\ttotal: 832ms\tremaining: 6.22s\n",
      "118:\tlearn: 0.4077122\ttotal: 835ms\tremaining: 6.18s\n",
      "119:\tlearn: 0.4074527\ttotal: 838ms\tremaining: 6.15s\n",
      "120:\tlearn: 0.4072454\ttotal: 843ms\tremaining: 6.13s\n",
      "121:\tlearn: 0.4069488\ttotal: 849ms\tremaining: 6.11s\n",
      "122:\tlearn: 0.4066997\ttotal: 852ms\tremaining: 6.08s\n",
      "123:\tlearn: 0.4064645\ttotal: 857ms\tremaining: 6.06s\n",
      "124:\tlearn: 0.4062329\ttotal: 861ms\tremaining: 6.03s\n",
      "125:\tlearn: 0.4060827\ttotal: 864ms\tremaining: 6s\n",
      "126:\tlearn: 0.4058776\ttotal: 867ms\tremaining: 5.96s\n",
      "127:\tlearn: 0.4056573\ttotal: 870ms\tremaining: 5.93s\n",
      "128:\tlearn: 0.4054097\ttotal: 874ms\tremaining: 5.9s\n",
      "129:\tlearn: 0.4052378\ttotal: 878ms\tremaining: 5.87s\n",
      "130:\tlearn: 0.4049756\ttotal: 880ms\tremaining: 5.84s\n",
      "131:\tlearn: 0.4047924\ttotal: 883ms\tremaining: 5.81s\n",
      "132:\tlearn: 0.4045025\ttotal: 887ms\tremaining: 5.78s\n",
      "133:\tlearn: 0.4042718\ttotal: 890ms\tremaining: 5.75s\n",
      "134:\tlearn: 0.4040673\ttotal: 892ms\tremaining: 5.71s\n",
      "135:\tlearn: 0.4038891\ttotal: 894ms\tremaining: 5.68s\n",
      "136:\tlearn: 0.4036756\ttotal: 896ms\tremaining: 5.64s\n",
      "137:\tlearn: 0.4034325\ttotal: 898ms\tremaining: 5.61s\n",
      "138:\tlearn: 0.4031655\ttotal: 899ms\tremaining: 5.57s\n",
      "139:\tlearn: 0.4030564\ttotal: 901ms\tremaining: 5.54s\n",
      "140:\tlearn: 0.4028446\ttotal: 903ms\tremaining: 5.5s\n",
      "141:\tlearn: 0.4026865\ttotal: 905ms\tremaining: 5.47s\n",
      "142:\tlearn: 0.4025807\ttotal: 907ms\tremaining: 5.44s\n",
      "143:\tlearn: 0.4023349\ttotal: 909ms\tremaining: 5.4s\n",
      "144:\tlearn: 0.4020918\ttotal: 911ms\tremaining: 5.37s\n",
      "145:\tlearn: 0.4019826\ttotal: 912ms\tremaining: 5.34s\n",
      "146:\tlearn: 0.4017912\ttotal: 914ms\tremaining: 5.3s\n",
      "147:\tlearn: 0.4016160\ttotal: 916ms\tremaining: 5.27s\n",
      "148:\tlearn: 0.4014439\ttotal: 918ms\tremaining: 5.24s\n",
      "149:\tlearn: 0.4012960\ttotal: 921ms\tremaining: 5.22s\n",
      "150:\tlearn: 0.4012736\ttotal: 923ms\tremaining: 5.19s\n",
      "151:\tlearn: 0.4010914\ttotal: 925ms\tremaining: 5.16s\n",
      "152:\tlearn: 0.4007959\ttotal: 927ms\tremaining: 5.13s\n",
      "153:\tlearn: 0.4006542\ttotal: 929ms\tremaining: 5.1s\n",
      "154:\tlearn: 0.4005096\ttotal: 931ms\tremaining: 5.07s\n",
      "155:\tlearn: 0.4003672\ttotal: 932ms\tremaining: 5.04s\n",
      "156:\tlearn: 0.4003350\ttotal: 934ms\tremaining: 5.01s\n",
      "157:\tlearn: 0.4001616\ttotal: 936ms\tremaining: 4.99s\n",
      "158:\tlearn: 0.4000595\ttotal: 938ms\tremaining: 4.96s\n",
      "159:\tlearn: 0.3998733\ttotal: 940ms\tremaining: 4.93s\n",
      "160:\tlearn: 0.3996482\ttotal: 941ms\tremaining: 4.91s\n",
      "161:\tlearn: 0.3995323\ttotal: 943ms\tremaining: 4.88s\n",
      "162:\tlearn: 0.3993228\ttotal: 945ms\tremaining: 4.85s\n",
      "163:\tlearn: 0.3990706\ttotal: 947ms\tremaining: 4.83s\n",
      "164:\tlearn: 0.3989191\ttotal: 949ms\tremaining: 4.8s\n",
      "165:\tlearn: 0.3987825\ttotal: 951ms\tremaining: 4.78s\n",
      "166:\tlearn: 0.3987012\ttotal: 954ms\tremaining: 4.76s\n",
      "167:\tlearn: 0.3985412\ttotal: 956ms\tremaining: 4.74s\n",
      "168:\tlearn: 0.3983984\ttotal: 958ms\tremaining: 4.71s\n",
      "169:\tlearn: 0.3982508\ttotal: 960ms\tremaining: 4.68s\n",
      "170:\tlearn: 0.3981160\ttotal: 961ms\tremaining: 4.66s\n",
      "171:\tlearn: 0.3979850\ttotal: 963ms\tremaining: 4.63s\n",
      "172:\tlearn: 0.3977813\ttotal: 967ms\tremaining: 4.62s\n",
      "173:\tlearn: 0.3975687\ttotal: 969ms\tremaining: 4.6s\n",
      "174:\tlearn: 0.3973281\ttotal: 971ms\tremaining: 4.58s\n",
      "175:\tlearn: 0.3971780\ttotal: 974ms\tremaining: 4.56s\n",
      "176:\tlearn: 0.3969914\ttotal: 976ms\tremaining: 4.54s\n",
      "177:\tlearn: 0.3967680\ttotal: 977ms\tremaining: 4.51s\n",
      "178:\tlearn: 0.3966287\ttotal: 981ms\tremaining: 4.5s\n",
      "179:\tlearn: 0.3964535\ttotal: 983ms\tremaining: 4.48s\n",
      "180:\tlearn: 0.3963518\ttotal: 985ms\tremaining: 4.46s\n",
      "181:\tlearn: 0.3961025\ttotal: 987ms\tremaining: 4.44s\n",
      "182:\tlearn: 0.3959850\ttotal: 989ms\tremaining: 4.42s\n",
      "183:\tlearn: 0.3958855\ttotal: 991ms\tremaining: 4.39s\n",
      "184:\tlearn: 0.3956896\ttotal: 993ms\tremaining: 4.37s\n",
      "185:\tlearn: 0.3956100\ttotal: 994ms\tremaining: 4.35s\n",
      "186:\tlearn: 0.3955783\ttotal: 996ms\tremaining: 4.33s\n",
      "187:\tlearn: 0.3954602\ttotal: 998ms\tremaining: 4.31s\n",
      "188:\tlearn: 0.3953283\ttotal: 1s\tremaining: 4.29s\n",
      "189:\tlearn: 0.3953024\ttotal: 1s\tremaining: 4.27s\n",
      "190:\tlearn: 0.3951482\ttotal: 1s\tremaining: 4.25s\n",
      "191:\tlearn: 0.3949924\ttotal: 1s\tremaining: 4.23s\n",
      "192:\tlearn: 0.3948402\ttotal: 1.01s\tremaining: 4.21s\n",
      "193:\tlearn: 0.3947054\ttotal: 1.01s\tremaining: 4.19s\n",
      "194:\tlearn: 0.3947020\ttotal: 1.01s\tremaining: 4.17s\n",
      "195:\tlearn: 0.3945188\ttotal: 1.01s\tremaining: 4.15s\n",
      "196:\tlearn: 0.3943705\ttotal: 1.01s\tremaining: 4.13s\n",
      "197:\tlearn: 0.3941706\ttotal: 1.02s\tremaining: 4.12s\n",
      "198:\tlearn: 0.3939791\ttotal: 1.02s\tremaining: 4.1s\n",
      "199:\tlearn: 0.3938318\ttotal: 1.02s\tremaining: 4.09s\n",
      "200:\tlearn: 0.3936330\ttotal: 1.02s\tremaining: 4.07s\n",
      "201:\tlearn: 0.3935321\ttotal: 1.03s\tremaining: 4.05s\n",
      "202:\tlearn: 0.3934394\ttotal: 1.03s\tremaining: 4.04s\n",
      "203:\tlearn: 0.3932978\ttotal: 1.03s\tremaining: 4.02s\n",
      "204:\tlearn: 0.3932830\ttotal: 1.03s\tremaining: 4s\n",
      "205:\tlearn: 0.3932072\ttotal: 1.03s\tremaining: 3.99s\n",
      "206:\tlearn: 0.3929486\ttotal: 1.04s\tremaining: 3.97s\n",
      "207:\tlearn: 0.3927273\ttotal: 1.04s\tremaining: 3.95s\n",
      "208:\tlearn: 0.3926425\ttotal: 1.04s\tremaining: 3.94s\n",
      "209:\tlearn: 0.3925026\ttotal: 1.04s\tremaining: 3.92s\n",
      "210:\tlearn: 0.3923569\ttotal: 1.04s\tremaining: 3.91s\n",
      "211:\tlearn: 0.3922224\ttotal: 1.05s\tremaining: 3.9s\n",
      "212:\tlearn: 0.3921117\ttotal: 1.05s\tremaining: 3.88s\n",
      "213:\tlearn: 0.3919954\ttotal: 1.05s\tremaining: 3.87s\n",
      "214:\tlearn: 0.3918071\ttotal: 1.05s\tremaining: 3.85s\n",
      "215:\tlearn: 0.3917254\ttotal: 1.06s\tremaining: 3.83s\n",
      "216:\tlearn: 0.3915455\ttotal: 1.06s\tremaining: 3.82s\n",
      "217:\tlearn: 0.3913929\ttotal: 1.06s\tremaining: 3.81s\n",
      "218:\tlearn: 0.3912459\ttotal: 1.06s\tremaining: 3.79s\n",
      "219:\tlearn: 0.3910596\ttotal: 1.06s\tremaining: 3.78s\n",
      "220:\tlearn: 0.3909232\ttotal: 1.07s\tremaining: 3.76s\n",
      "221:\tlearn: 0.3908329\ttotal: 1.07s\tremaining: 3.75s\n",
      "222:\tlearn: 0.3906969\ttotal: 1.07s\tremaining: 3.73s\n",
      "223:\tlearn: 0.3905752\ttotal: 1.07s\tremaining: 3.72s\n",
      "224:\tlearn: 0.3904228\ttotal: 1.08s\tremaining: 3.71s\n",
      "225:\tlearn: 0.3903099\ttotal: 1.08s\tremaining: 3.7s\n",
      "226:\tlearn: 0.3902310\ttotal: 1.08s\tremaining: 3.68s\n",
      "227:\tlearn: 0.3901581\ttotal: 1.08s\tremaining: 3.67s\n",
      "228:\tlearn: 0.3900737\ttotal: 1.09s\tremaining: 3.66s\n",
      "229:\tlearn: 0.3899223\ttotal: 1.09s\tremaining: 3.65s\n",
      "230:\tlearn: 0.3898249\ttotal: 1.09s\tremaining: 3.63s\n",
      "231:\tlearn: 0.3896789\ttotal: 1.09s\tremaining: 3.62s\n",
      "232:\tlearn: 0.3896366\ttotal: 1.09s\tremaining: 3.6s\n",
      "233:\tlearn: 0.3896328\ttotal: 1.1s\tremaining: 3.59s\n",
      "234:\tlearn: 0.3894746\ttotal: 1.1s\tremaining: 3.58s\n",
      "235:\tlearn: 0.3893605\ttotal: 1.1s\tremaining: 3.56s\n",
      "236:\tlearn: 0.3892869\ttotal: 1.1s\tremaining: 3.55s\n",
      "237:\tlearn: 0.3892527\ttotal: 1.1s\tremaining: 3.54s\n",
      "238:\tlearn: 0.3891661\ttotal: 1.11s\tremaining: 3.52s\n",
      "239:\tlearn: 0.3891349\ttotal: 1.11s\tremaining: 3.51s\n",
      "240:\tlearn: 0.3889721\ttotal: 1.11s\tremaining: 3.5s\n",
      "241:\tlearn: 0.3888129\ttotal: 1.11s\tremaining: 3.49s\n",
      "242:\tlearn: 0.3886785\ttotal: 1.11s\tremaining: 3.48s\n",
      "243:\tlearn: 0.3886680\ttotal: 1.12s\tremaining: 3.46s\n",
      "244:\tlearn: 0.3885383\ttotal: 1.12s\tremaining: 3.45s\n",
      "245:\tlearn: 0.3884089\ttotal: 1.12s\tremaining: 3.44s\n",
      "246:\tlearn: 0.3882901\ttotal: 1.12s\tremaining: 3.42s\n",
      "247:\tlearn: 0.3882470\ttotal: 1.13s\tremaining: 3.41s\n",
      "248:\tlearn: 0.3880818\ttotal: 1.13s\tremaining: 3.4s\n",
      "249:\tlearn: 0.3878923\ttotal: 1.13s\tremaining: 3.39s\n",
      "250:\tlearn: 0.3877987\ttotal: 1.13s\tremaining: 3.38s\n",
      "251:\tlearn: 0.3876607\ttotal: 1.13s\tremaining: 3.36s\n",
      "252:\tlearn: 0.3875580\ttotal: 1.14s\tremaining: 3.35s\n",
      "253:\tlearn: 0.3875545\ttotal: 1.14s\tremaining: 3.34s\n",
      "254:\tlearn: 0.3874059\ttotal: 1.14s\tremaining: 3.33s\n",
      "255:\tlearn: 0.3872567\ttotal: 1.14s\tremaining: 3.32s\n",
      "256:\tlearn: 0.3871713\ttotal: 1.14s\tremaining: 3.31s\n",
      "257:\tlearn: 0.3870763\ttotal: 1.15s\tremaining: 3.3s\n",
      "258:\tlearn: 0.3870002\ttotal: 1.15s\tremaining: 3.29s\n",
      "259:\tlearn: 0.3868658\ttotal: 1.15s\tremaining: 3.28s\n",
      "260:\tlearn: 0.3867051\ttotal: 1.15s\tremaining: 3.27s\n",
      "261:\tlearn: 0.3866200\ttotal: 1.16s\tremaining: 3.25s\n",
      "262:\tlearn: 0.3864430\ttotal: 1.16s\tremaining: 3.24s\n",
      "263:\tlearn: 0.3863286\ttotal: 1.16s\tremaining: 3.23s\n",
      "264:\tlearn: 0.3861428\ttotal: 1.16s\tremaining: 3.23s\n",
      "265:\tlearn: 0.3860089\ttotal: 1.17s\tremaining: 3.22s\n",
      "266:\tlearn: 0.3858169\ttotal: 1.17s\tremaining: 3.21s\n",
      "267:\tlearn: 0.3855592\ttotal: 1.17s\tremaining: 3.2s\n",
      "268:\tlearn: 0.3854017\ttotal: 1.17s\tremaining: 3.19s\n",
      "269:\tlearn: 0.3852260\ttotal: 1.18s\tremaining: 3.18s\n",
      "270:\tlearn: 0.3851454\ttotal: 1.18s\tremaining: 3.17s\n",
      "271:\tlearn: 0.3850663\ttotal: 1.18s\tremaining: 3.15s\n",
      "272:\tlearn: 0.3849477\ttotal: 1.18s\tremaining: 3.14s\n",
      "273:\tlearn: 0.3848841\ttotal: 1.18s\tremaining: 3.13s\n",
      "274:\tlearn: 0.3848803\ttotal: 1.18s\tremaining: 3.12s\n",
      "275:\tlearn: 0.3847832\ttotal: 1.19s\tremaining: 3.11s\n",
      "276:\tlearn: 0.3845753\ttotal: 1.19s\tremaining: 3.1s\n",
      "277:\tlearn: 0.3843628\ttotal: 1.19s\tremaining: 3.09s\n",
      "278:\tlearn: 0.3843116\ttotal: 1.19s\tremaining: 3.08s\n",
      "279:\tlearn: 0.3841869\ttotal: 1.19s\tremaining: 3.07s\n",
      "280:\tlearn: 0.3839535\ttotal: 1.2s\tremaining: 3.06s\n",
      "281:\tlearn: 0.3838411\ttotal: 1.2s\tremaining: 3.05s\n",
      "282:\tlearn: 0.3837292\ttotal: 1.2s\tremaining: 3.04s\n",
      "283:\tlearn: 0.3837290\ttotal: 1.2s\tremaining: 3.03s\n",
      "284:\tlearn: 0.3836609\ttotal: 1.21s\tremaining: 3.02s\n",
      "285:\tlearn: 0.3835891\ttotal: 1.21s\tremaining: 3.01s\n",
      "286:\tlearn: 0.3834952\ttotal: 1.21s\tremaining: 3s\n",
      "287:\tlearn: 0.3833936\ttotal: 1.21s\tremaining: 2.99s\n",
      "288:\tlearn: 0.3833306\ttotal: 1.21s\tremaining: 2.98s\n",
      "289:\tlearn: 0.3833285\ttotal: 1.21s\tremaining: 2.97s\n",
      "290:\tlearn: 0.3831940\ttotal: 1.22s\tremaining: 2.96s\n",
      "291:\tlearn: 0.3830936\ttotal: 1.22s\tremaining: 2.95s\n",
      "292:\tlearn: 0.3829841\ttotal: 1.22s\tremaining: 2.94s\n",
      "293:\tlearn: 0.3828590\ttotal: 1.22s\tremaining: 2.93s\n",
      "294:\tlearn: 0.3827448\ttotal: 1.22s\tremaining: 2.92s\n",
      "295:\tlearn: 0.3827374\ttotal: 1.23s\tremaining: 2.92s\n",
      "296:\tlearn: 0.3825440\ttotal: 1.23s\tremaining: 2.91s\n",
      "297:\tlearn: 0.3824344\ttotal: 1.23s\tremaining: 2.9s\n",
      "298:\tlearn: 0.3823730\ttotal: 1.23s\tremaining: 2.89s\n",
      "299:\tlearn: 0.3822735\ttotal: 1.24s\tremaining: 2.88s\n",
      "300:\tlearn: 0.3821169\ttotal: 1.24s\tremaining: 2.88s\n",
      "301:\tlearn: 0.3820343\ttotal: 1.24s\tremaining: 2.87s\n",
      "302:\tlearn: 0.3818499\ttotal: 1.24s\tremaining: 2.86s\n",
      "303:\tlearn: 0.3816639\ttotal: 1.25s\tremaining: 2.85s\n",
      "304:\tlearn: 0.3815708\ttotal: 1.25s\tremaining: 2.84s\n",
      "305:\tlearn: 0.3814072\ttotal: 1.25s\tremaining: 2.83s\n",
      "306:\tlearn: 0.3812965\ttotal: 1.25s\tremaining: 2.83s\n",
      "307:\tlearn: 0.3811741\ttotal: 1.25s\tremaining: 2.82s\n",
      "308:\tlearn: 0.3810363\ttotal: 1.26s\tremaining: 2.81s\n",
      "309:\tlearn: 0.3809493\ttotal: 1.26s\tremaining: 2.8s\n",
      "310:\tlearn: 0.3808216\ttotal: 1.26s\tremaining: 2.79s\n",
      "311:\tlearn: 0.3807141\ttotal: 1.26s\tremaining: 2.78s\n",
      "312:\tlearn: 0.3806266\ttotal: 1.26s\tremaining: 2.77s\n",
      "313:\tlearn: 0.3805120\ttotal: 1.27s\tremaining: 2.77s\n",
      "314:\tlearn: 0.3802927\ttotal: 1.27s\tremaining: 2.76s\n",
      "315:\tlearn: 0.3801330\ttotal: 1.27s\tremaining: 2.75s\n",
      "316:\tlearn: 0.3801098\ttotal: 1.27s\tremaining: 2.74s\n",
      "317:\tlearn: 0.3800134\ttotal: 1.27s\tremaining: 2.73s\n",
      "318:\tlearn: 0.3798844\ttotal: 1.27s\tremaining: 2.72s\n",
      "319:\tlearn: 0.3798677\ttotal: 1.28s\tremaining: 2.71s\n",
      "320:\tlearn: 0.3797462\ttotal: 1.28s\tremaining: 2.71s\n",
      "321:\tlearn: 0.3796427\ttotal: 1.28s\tremaining: 2.7s\n",
      "322:\tlearn: 0.3795387\ttotal: 1.28s\tremaining: 2.69s\n",
      "323:\tlearn: 0.3794903\ttotal: 1.28s\tremaining: 2.68s\n",
      "324:\tlearn: 0.3793671\ttotal: 1.29s\tremaining: 2.67s\n",
      "325:\tlearn: 0.3792282\ttotal: 1.29s\tremaining: 2.67s\n",
      "326:\tlearn: 0.3791550\ttotal: 1.29s\tremaining: 2.66s\n",
      "327:\tlearn: 0.3791158\ttotal: 1.29s\tremaining: 2.65s\n",
      "328:\tlearn: 0.3790010\ttotal: 1.29s\tremaining: 2.64s\n",
      "329:\tlearn: 0.3789100\ttotal: 1.3s\tremaining: 2.63s\n",
      "330:\tlearn: 0.3788368\ttotal: 1.3s\tremaining: 2.63s\n",
      "331:\tlearn: 0.3787376\ttotal: 1.3s\tremaining: 2.62s\n",
      "332:\tlearn: 0.3786315\ttotal: 1.31s\tremaining: 2.62s\n",
      "333:\tlearn: 0.3786036\ttotal: 1.31s\tremaining: 2.61s\n",
      "334:\tlearn: 0.3784752\ttotal: 1.31s\tremaining: 2.6s\n",
      "335:\tlearn: 0.3784091\ttotal: 1.31s\tremaining: 2.59s\n",
      "336:\tlearn: 0.3782870\ttotal: 1.31s\tremaining: 2.59s\n",
      "337:\tlearn: 0.3781667\ttotal: 1.32s\tremaining: 2.58s\n",
      "338:\tlearn: 0.3780695\ttotal: 1.32s\tremaining: 2.57s\n",
      "339:\tlearn: 0.3778959\ttotal: 1.32s\tremaining: 2.56s\n",
      "340:\tlearn: 0.3777437\ttotal: 1.32s\tremaining: 2.56s\n",
      "341:\tlearn: 0.3775849\ttotal: 1.33s\tremaining: 2.55s\n",
      "342:\tlearn: 0.3774555\ttotal: 1.33s\tremaining: 2.55s\n",
      "343:\tlearn: 0.3774491\ttotal: 1.33s\tremaining: 2.54s\n",
      "344:\tlearn: 0.3773063\ttotal: 1.33s\tremaining: 2.54s\n",
      "345:\tlearn: 0.3772864\ttotal: 1.34s\tremaining: 2.53s\n",
      "346:\tlearn: 0.3772148\ttotal: 1.34s\tremaining: 2.52s\n",
      "347:\tlearn: 0.3771347\ttotal: 1.34s\tremaining: 2.52s\n",
      "348:\tlearn: 0.3770637\ttotal: 1.35s\tremaining: 2.51s\n",
      "349:\tlearn: 0.3769838\ttotal: 1.35s\tremaining: 2.5s\n",
      "350:\tlearn: 0.3768529\ttotal: 1.35s\tremaining: 2.5s\n",
      "351:\tlearn: 0.3767989\ttotal: 1.35s\tremaining: 2.49s\n",
      "352:\tlearn: 0.3766732\ttotal: 1.36s\tremaining: 2.49s\n",
      "353:\tlearn: 0.3765653\ttotal: 1.36s\tremaining: 2.48s\n",
      "354:\tlearn: 0.3764495\ttotal: 1.36s\tremaining: 2.47s\n",
      "355:\tlearn: 0.3762870\ttotal: 1.36s\tremaining: 2.47s\n",
      "356:\tlearn: 0.3761653\ttotal: 1.37s\tremaining: 2.46s\n",
      "357:\tlearn: 0.3760978\ttotal: 1.37s\tremaining: 2.46s\n",
      "358:\tlearn: 0.3760330\ttotal: 1.37s\tremaining: 2.45s\n",
      "359:\tlearn: 0.3760259\ttotal: 1.37s\tremaining: 2.44s\n",
      "360:\tlearn: 0.3759162\ttotal: 1.38s\tremaining: 2.43s\n",
      "361:\tlearn: 0.3758444\ttotal: 1.38s\tremaining: 2.43s\n",
      "362:\tlearn: 0.3757658\ttotal: 1.38s\tremaining: 2.42s\n",
      "363:\tlearn: 0.3756356\ttotal: 1.38s\tremaining: 2.41s\n",
      "364:\tlearn: 0.3754895\ttotal: 1.38s\tremaining: 2.41s\n",
      "365:\tlearn: 0.3753916\ttotal: 1.39s\tremaining: 2.4s\n",
      "366:\tlearn: 0.3752837\ttotal: 1.39s\tremaining: 2.4s\n",
      "367:\tlearn: 0.3752570\ttotal: 1.39s\tremaining: 2.39s\n",
      "368:\tlearn: 0.3751221\ttotal: 1.4s\tremaining: 2.39s\n",
      "369:\tlearn: 0.3750097\ttotal: 1.4s\tremaining: 2.38s\n",
      "370:\tlearn: 0.3748799\ttotal: 1.4s\tremaining: 2.37s\n",
      "371:\tlearn: 0.3747966\ttotal: 1.4s\tremaining: 2.37s\n",
      "372:\tlearn: 0.3746895\ttotal: 1.4s\tremaining: 2.36s\n",
      "373:\tlearn: 0.3745388\ttotal: 1.41s\tremaining: 2.35s\n",
      "374:\tlearn: 0.3744229\ttotal: 1.41s\tremaining: 2.35s\n",
      "375:\tlearn: 0.3743625\ttotal: 1.41s\tremaining: 2.34s\n",
      "376:\tlearn: 0.3742125\ttotal: 1.41s\tremaining: 2.33s\n",
      "377:\tlearn: 0.3741412\ttotal: 1.41s\tremaining: 2.33s\n",
      "378:\tlearn: 0.3740918\ttotal: 1.42s\tremaining: 2.32s\n",
      "379:\tlearn: 0.3739704\ttotal: 1.42s\tremaining: 2.31s\n",
      "380:\tlearn: 0.3738429\ttotal: 1.42s\tremaining: 2.31s\n",
      "381:\tlearn: 0.3737268\ttotal: 1.42s\tremaining: 2.3s\n",
      "382:\tlearn: 0.3736286\ttotal: 1.42s\tremaining: 2.29s\n",
      "383:\tlearn: 0.3735012\ttotal: 1.43s\tremaining: 2.29s\n",
      "384:\tlearn: 0.3734466\ttotal: 1.43s\tremaining: 2.28s\n",
      "385:\tlearn: 0.3733113\ttotal: 1.43s\tremaining: 2.27s\n",
      "386:\tlearn: 0.3732504\ttotal: 1.43s\tremaining: 2.27s\n",
      "387:\tlearn: 0.3730969\ttotal: 1.43s\tremaining: 2.26s\n",
      "388:\tlearn: 0.3729420\ttotal: 1.44s\tremaining: 2.26s\n",
      "389:\tlearn: 0.3729318\ttotal: 1.44s\tremaining: 2.25s\n",
      "390:\tlearn: 0.3728012\ttotal: 1.44s\tremaining: 2.24s\n",
      "391:\tlearn: 0.3726940\ttotal: 1.44s\tremaining: 2.24s\n",
      "392:\tlearn: 0.3725764\ttotal: 1.44s\tremaining: 2.23s\n",
      "393:\tlearn: 0.3725032\ttotal: 1.45s\tremaining: 2.22s\n",
      "394:\tlearn: 0.3724267\ttotal: 1.45s\tremaining: 2.22s\n",
      "395:\tlearn: 0.3723562\ttotal: 1.45s\tremaining: 2.21s\n",
      "396:\tlearn: 0.3722734\ttotal: 1.45s\tremaining: 2.21s\n",
      "397:\tlearn: 0.3721617\ttotal: 1.45s\tremaining: 2.2s\n",
      "398:\tlearn: 0.3720517\ttotal: 1.46s\tremaining: 2.19s\n",
      "399:\tlearn: 0.3719850\ttotal: 1.46s\tremaining: 2.19s\n",
      "400:\tlearn: 0.3719273\ttotal: 1.46s\tremaining: 2.18s\n",
      "401:\tlearn: 0.3718537\ttotal: 1.46s\tremaining: 2.17s\n",
      "402:\tlearn: 0.3717194\ttotal: 1.46s\tremaining: 2.17s\n",
      "403:\tlearn: 0.3716428\ttotal: 1.47s\tremaining: 2.16s\n",
      "404:\tlearn: 0.3714625\ttotal: 1.47s\tremaining: 2.16s\n",
      "405:\tlearn: 0.3712668\ttotal: 1.47s\tremaining: 2.15s\n",
      "406:\tlearn: 0.3711244\ttotal: 1.47s\tremaining: 2.14s\n",
      "407:\tlearn: 0.3709795\ttotal: 1.47s\tremaining: 2.14s\n",
      "408:\tlearn: 0.3708564\ttotal: 1.48s\tremaining: 2.13s\n",
      "409:\tlearn: 0.3707577\ttotal: 1.48s\tremaining: 2.13s\n",
      "410:\tlearn: 0.3706434\ttotal: 1.48s\tremaining: 2.12s\n",
      "411:\tlearn: 0.3705410\ttotal: 1.48s\tremaining: 2.11s\n",
      "412:\tlearn: 0.3704438\ttotal: 1.48s\tremaining: 2.11s\n",
      "413:\tlearn: 0.3703255\ttotal: 1.48s\tremaining: 2.1s\n",
      "414:\tlearn: 0.3702300\ttotal: 1.49s\tremaining: 2.1s\n",
      "415:\tlearn: 0.3701229\ttotal: 1.49s\tremaining: 2.09s\n",
      "416:\tlearn: 0.3700376\ttotal: 1.49s\tremaining: 2.08s\n",
      "417:\tlearn: 0.3699511\ttotal: 1.49s\tremaining: 2.08s\n",
      "418:\tlearn: 0.3698208\ttotal: 1.5s\tremaining: 2.07s\n",
      "419:\tlearn: 0.3697607\ttotal: 1.5s\tremaining: 2.07s\n",
      "420:\tlearn: 0.3697011\ttotal: 1.5s\tremaining: 2.06s\n",
      "421:\tlearn: 0.3696130\ttotal: 1.5s\tremaining: 2.06s\n",
      "422:\tlearn: 0.3695026\ttotal: 1.5s\tremaining: 2.05s\n",
      "423:\tlearn: 0.3693930\ttotal: 1.5s\tremaining: 2.04s\n",
      "424:\tlearn: 0.3693371\ttotal: 1.51s\tremaining: 2.04s\n",
      "425:\tlearn: 0.3692290\ttotal: 1.51s\tremaining: 2.03s\n",
      "426:\tlearn: 0.3691185\ttotal: 1.51s\tremaining: 2.03s\n",
      "427:\tlearn: 0.3689658\ttotal: 1.51s\tremaining: 2.02s\n",
      "428:\tlearn: 0.3687969\ttotal: 1.51s\tremaining: 2.02s\n",
      "429:\tlearn: 0.3687037\ttotal: 1.52s\tremaining: 2.01s\n",
      "430:\tlearn: 0.3686235\ttotal: 1.52s\tremaining: 2.01s\n",
      "431:\tlearn: 0.3685374\ttotal: 1.52s\tremaining: 2s\n",
      "432:\tlearn: 0.3684379\ttotal: 1.52s\tremaining: 2s\n",
      "433:\tlearn: 0.3683616\ttotal: 1.53s\tremaining: 1.99s\n",
      "434:\tlearn: 0.3681924\ttotal: 1.53s\tremaining: 1.99s\n",
      "435:\tlearn: 0.3681256\ttotal: 1.53s\tremaining: 1.98s\n",
      "436:\tlearn: 0.3680370\ttotal: 1.53s\tremaining: 1.98s\n",
      "437:\tlearn: 0.3679169\ttotal: 1.54s\tremaining: 1.97s\n",
      "438:\tlearn: 0.3678383\ttotal: 1.54s\tremaining: 1.97s\n",
      "439:\tlearn: 0.3677467\ttotal: 1.54s\tremaining: 1.96s\n",
      "440:\tlearn: 0.3676374\ttotal: 1.54s\tremaining: 1.96s\n",
      "441:\tlearn: 0.3674807\ttotal: 1.55s\tremaining: 1.95s\n",
      "442:\tlearn: 0.3673625\ttotal: 1.55s\tremaining: 1.95s\n",
      "443:\tlearn: 0.3672705\ttotal: 1.55s\tremaining: 1.94s\n",
      "444:\tlearn: 0.3671293\ttotal: 1.55s\tremaining: 1.94s\n",
      "445:\tlearn: 0.3670484\ttotal: 1.56s\tremaining: 1.93s\n",
      "446:\tlearn: 0.3669220\ttotal: 1.56s\tremaining: 1.93s\n",
      "447:\tlearn: 0.3668306\ttotal: 1.56s\tremaining: 1.92s\n",
      "448:\tlearn: 0.3667190\ttotal: 1.56s\tremaining: 1.92s\n",
      "449:\tlearn: 0.3666626\ttotal: 1.57s\tremaining: 1.91s\n",
      "450:\tlearn: 0.3665693\ttotal: 1.57s\tremaining: 1.91s\n",
      "451:\tlearn: 0.3664674\ttotal: 1.57s\tremaining: 1.9s\n",
      "452:\tlearn: 0.3663386\ttotal: 1.57s\tremaining: 1.9s\n",
      "453:\tlearn: 0.3662636\ttotal: 1.57s\tremaining: 1.89s\n",
      "454:\tlearn: 0.3661607\ttotal: 1.58s\tremaining: 1.89s\n",
      "455:\tlearn: 0.3659983\ttotal: 1.58s\tremaining: 1.89s\n",
      "456:\tlearn: 0.3659222\ttotal: 1.58s\tremaining: 1.88s\n",
      "457:\tlearn: 0.3657889\ttotal: 1.58s\tremaining: 1.88s\n",
      "458:\tlearn: 0.3656563\ttotal: 1.59s\tremaining: 1.87s\n",
      "459:\tlearn: 0.3655505\ttotal: 1.59s\tremaining: 1.87s\n",
      "460:\tlearn: 0.3654493\ttotal: 1.59s\tremaining: 1.86s\n",
      "461:\tlearn: 0.3652802\ttotal: 1.59s\tremaining: 1.86s\n",
      "462:\tlearn: 0.3651534\ttotal: 1.6s\tremaining: 1.85s\n",
      "463:\tlearn: 0.3650084\ttotal: 1.6s\tremaining: 1.85s\n",
      "464:\tlearn: 0.3648780\ttotal: 1.6s\tremaining: 1.84s\n",
      "465:\tlearn: 0.3648113\ttotal: 1.6s\tremaining: 1.84s\n",
      "466:\tlearn: 0.3646612\ttotal: 1.6s\tremaining: 1.83s\n",
      "467:\tlearn: 0.3645730\ttotal: 1.61s\tremaining: 1.83s\n",
      "468:\tlearn: 0.3644553\ttotal: 1.61s\tremaining: 1.82s\n",
      "469:\tlearn: 0.3643651\ttotal: 1.61s\tremaining: 1.82s\n",
      "470:\tlearn: 0.3642427\ttotal: 1.61s\tremaining: 1.81s\n",
      "471:\tlearn: 0.3640660\ttotal: 1.61s\tremaining: 1.8s\n",
      "472:\tlearn: 0.3639452\ttotal: 1.62s\tremaining: 1.8s\n",
      "473:\tlearn: 0.3637892\ttotal: 1.62s\tremaining: 1.8s\n",
      "474:\tlearn: 0.3636790\ttotal: 1.62s\tremaining: 1.79s\n",
      "475:\tlearn: 0.3635934\ttotal: 1.62s\tremaining: 1.78s\n",
      "476:\tlearn: 0.3634846\ttotal: 1.62s\tremaining: 1.78s\n",
      "477:\tlearn: 0.3633573\ttotal: 1.63s\tremaining: 1.77s\n",
      "478:\tlearn: 0.3632230\ttotal: 1.63s\tremaining: 1.77s\n",
      "479:\tlearn: 0.3631308\ttotal: 1.63s\tremaining: 1.76s\n",
      "480:\tlearn: 0.3630151\ttotal: 1.63s\tremaining: 1.76s\n",
      "481:\tlearn: 0.3629382\ttotal: 1.63s\tremaining: 1.75s\n",
      "482:\tlearn: 0.3627972\ttotal: 1.64s\tremaining: 1.75s\n",
      "483:\tlearn: 0.3627411\ttotal: 1.64s\tremaining: 1.75s\n",
      "484:\tlearn: 0.3626301\ttotal: 1.64s\tremaining: 1.74s\n",
      "485:\tlearn: 0.3624894\ttotal: 1.64s\tremaining: 1.74s\n",
      "486:\tlearn: 0.3623840\ttotal: 1.64s\tremaining: 1.73s\n",
      "487:\tlearn: 0.3622355\ttotal: 1.65s\tremaining: 1.73s\n",
      "488:\tlearn: 0.3621356\ttotal: 1.65s\tremaining: 1.72s\n",
      "489:\tlearn: 0.3619996\ttotal: 1.65s\tremaining: 1.72s\n",
      "490:\tlearn: 0.3618862\ttotal: 1.65s\tremaining: 1.71s\n",
      "491:\tlearn: 0.3617681\ttotal: 1.65s\tremaining: 1.71s\n",
      "492:\tlearn: 0.3616491\ttotal: 1.66s\tremaining: 1.7s\n",
      "493:\tlearn: 0.3615579\ttotal: 1.66s\tremaining: 1.7s\n",
      "494:\tlearn: 0.3614801\ttotal: 1.66s\tremaining: 1.69s\n",
      "495:\tlearn: 0.3613924\ttotal: 1.66s\tremaining: 1.69s\n",
      "496:\tlearn: 0.3613086\ttotal: 1.66s\tremaining: 1.68s\n",
      "497:\tlearn: 0.3612248\ttotal: 1.67s\tremaining: 1.68s\n",
      "498:\tlearn: 0.3610773\ttotal: 1.67s\tremaining: 1.67s\n",
      "499:\tlearn: 0.3609632\ttotal: 1.67s\tremaining: 1.67s\n",
      "500:\tlearn: 0.3608018\ttotal: 1.67s\tremaining: 1.66s\n",
      "501:\tlearn: 0.3606948\ttotal: 1.67s\tremaining: 1.66s\n",
      "502:\tlearn: 0.3605849\ttotal: 1.68s\tremaining: 1.66s\n",
      "503:\tlearn: 0.3604789\ttotal: 1.68s\tremaining: 1.65s\n",
      "504:\tlearn: 0.3603883\ttotal: 1.68s\tremaining: 1.65s\n",
      "505:\tlearn: 0.3602449\ttotal: 1.68s\tremaining: 1.64s\n",
      "506:\tlearn: 0.3601538\ttotal: 1.68s\tremaining: 1.64s\n",
      "507:\tlearn: 0.3600436\ttotal: 1.69s\tremaining: 1.63s\n",
      "508:\tlearn: 0.3599257\ttotal: 1.69s\tremaining: 1.63s\n",
      "509:\tlearn: 0.3598318\ttotal: 1.69s\tremaining: 1.62s\n",
      "510:\tlearn: 0.3596971\ttotal: 1.69s\tremaining: 1.62s\n",
      "511:\tlearn: 0.3595618\ttotal: 1.69s\tremaining: 1.61s\n",
      "512:\tlearn: 0.3594905\ttotal: 1.7s\tremaining: 1.61s\n",
      "513:\tlearn: 0.3593834\ttotal: 1.7s\tremaining: 1.6s\n",
      "514:\tlearn: 0.3593136\ttotal: 1.7s\tremaining: 1.6s\n",
      "515:\tlearn: 0.3592398\ttotal: 1.7s\tremaining: 1.6s\n",
      "516:\tlearn: 0.3591285\ttotal: 1.71s\tremaining: 1.59s\n",
      "517:\tlearn: 0.3589973\ttotal: 1.71s\tremaining: 1.59s\n",
      "518:\tlearn: 0.3588988\ttotal: 1.71s\tremaining: 1.59s\n",
      "519:\tlearn: 0.3588264\ttotal: 1.71s\tremaining: 1.58s\n",
      "520:\tlearn: 0.3586256\ttotal: 1.72s\tremaining: 1.58s\n",
      "521:\tlearn: 0.3585244\ttotal: 1.72s\tremaining: 1.57s\n",
      "522:\tlearn: 0.3583593\ttotal: 1.72s\tremaining: 1.57s\n",
      "523:\tlearn: 0.3582442\ttotal: 1.72s\tremaining: 1.56s\n",
      "524:\tlearn: 0.3581899\ttotal: 1.73s\tremaining: 1.56s\n",
      "525:\tlearn: 0.3581034\ttotal: 1.73s\tremaining: 1.56s\n",
      "526:\tlearn: 0.3580075\ttotal: 1.73s\tremaining: 1.55s\n",
      "527:\tlearn: 0.3579170\ttotal: 1.73s\tremaining: 1.55s\n",
      "528:\tlearn: 0.3578227\ttotal: 1.74s\tremaining: 1.54s\n",
      "529:\tlearn: 0.3576845\ttotal: 1.74s\tremaining: 1.54s\n",
      "530:\tlearn: 0.3576171\ttotal: 1.74s\tremaining: 1.53s\n",
      "531:\tlearn: 0.3574711\ttotal: 1.74s\tremaining: 1.53s\n",
      "532:\tlearn: 0.3573651\ttotal: 1.74s\tremaining: 1.53s\n",
      "533:\tlearn: 0.3573073\ttotal: 1.75s\tremaining: 1.52s\n",
      "534:\tlearn: 0.3572125\ttotal: 1.75s\tremaining: 1.52s\n",
      "535:\tlearn: 0.3571276\ttotal: 1.75s\tremaining: 1.51s\n",
      "536:\tlearn: 0.3569384\ttotal: 1.75s\tremaining: 1.51s\n",
      "537:\tlearn: 0.3567768\ttotal: 1.75s\tremaining: 1.5s\n",
      "538:\tlearn: 0.3566885\ttotal: 1.75s\tremaining: 1.5s\n",
      "539:\tlearn: 0.3565977\ttotal: 1.76s\tremaining: 1.5s\n",
      "540:\tlearn: 0.3564698\ttotal: 1.76s\tremaining: 1.49s\n",
      "541:\tlearn: 0.3563551\ttotal: 1.76s\tremaining: 1.49s\n",
      "542:\tlearn: 0.3562609\ttotal: 1.76s\tremaining: 1.48s\n",
      "543:\tlearn: 0.3561546\ttotal: 1.76s\tremaining: 1.48s\n",
      "544:\tlearn: 0.3560016\ttotal: 1.77s\tremaining: 1.47s\n",
      "545:\tlearn: 0.3558581\ttotal: 1.77s\tremaining: 1.47s\n",
      "546:\tlearn: 0.3557399\ttotal: 1.77s\tremaining: 1.47s\n",
      "547:\tlearn: 0.3555846\ttotal: 1.77s\tremaining: 1.46s\n",
      "548:\tlearn: 0.3554724\ttotal: 1.77s\tremaining: 1.46s\n",
      "549:\tlearn: 0.3553345\ttotal: 1.78s\tremaining: 1.45s\n",
      "550:\tlearn: 0.3551992\ttotal: 1.78s\tremaining: 1.45s\n",
      "551:\tlearn: 0.3551134\ttotal: 1.78s\tremaining: 1.45s\n",
      "552:\tlearn: 0.3550118\ttotal: 1.78s\tremaining: 1.44s\n",
      "553:\tlearn: 0.3549171\ttotal: 1.78s\tremaining: 1.44s\n",
      "554:\tlearn: 0.3548108\ttotal: 1.79s\tremaining: 1.43s\n",
      "555:\tlearn: 0.3547565\ttotal: 1.79s\tremaining: 1.43s\n",
      "556:\tlearn: 0.3546778\ttotal: 1.79s\tremaining: 1.42s\n",
      "557:\tlearn: 0.3545543\ttotal: 1.79s\tremaining: 1.42s\n",
      "558:\tlearn: 0.3545129\ttotal: 1.79s\tremaining: 1.42s\n",
      "559:\tlearn: 0.3544069\ttotal: 1.8s\tremaining: 1.41s\n",
      "560:\tlearn: 0.3543014\ttotal: 1.8s\tremaining: 1.41s\n",
      "561:\tlearn: 0.3541206\ttotal: 1.8s\tremaining: 1.4s\n",
      "562:\tlearn: 0.3539781\ttotal: 1.8s\tremaining: 1.4s\n",
      "563:\tlearn: 0.3538694\ttotal: 1.8s\tremaining: 1.39s\n",
      "564:\tlearn: 0.3537211\ttotal: 1.81s\tremaining: 1.39s\n",
      "565:\tlearn: 0.3535753\ttotal: 1.81s\tremaining: 1.39s\n",
      "566:\tlearn: 0.3535061\ttotal: 1.81s\tremaining: 1.38s\n",
      "567:\tlearn: 0.3533315\ttotal: 1.81s\tremaining: 1.38s\n",
      "568:\tlearn: 0.3531650\ttotal: 1.81s\tremaining: 1.37s\n",
      "569:\tlearn: 0.3530430\ttotal: 1.81s\tremaining: 1.37s\n",
      "570:\tlearn: 0.3529677\ttotal: 1.82s\tremaining: 1.37s\n",
      "571:\tlearn: 0.3528957\ttotal: 1.82s\tremaining: 1.36s\n",
      "572:\tlearn: 0.3528266\ttotal: 1.82s\tremaining: 1.36s\n",
      "573:\tlearn: 0.3527380\ttotal: 1.82s\tremaining: 1.35s\n",
      "574:\tlearn: 0.3526718\ttotal: 1.83s\tremaining: 1.35s\n",
      "575:\tlearn: 0.3525657\ttotal: 1.83s\tremaining: 1.34s\n",
      "576:\tlearn: 0.3524915\ttotal: 1.83s\tremaining: 1.34s\n",
      "577:\tlearn: 0.3524841\ttotal: 1.83s\tremaining: 1.34s\n",
      "578:\tlearn: 0.3523703\ttotal: 1.83s\tremaining: 1.33s\n",
      "579:\tlearn: 0.3522327\ttotal: 1.83s\tremaining: 1.33s\n",
      "580:\tlearn: 0.3520945\ttotal: 1.84s\tremaining: 1.32s\n",
      "581:\tlearn: 0.3519609\ttotal: 1.84s\tremaining: 1.32s\n",
      "582:\tlearn: 0.3518278\ttotal: 1.84s\tremaining: 1.32s\n",
      "583:\tlearn: 0.3517670\ttotal: 1.84s\tremaining: 1.31s\n",
      "584:\tlearn: 0.3516238\ttotal: 1.84s\tremaining: 1.31s\n",
      "585:\tlearn: 0.3515261\ttotal: 1.85s\tremaining: 1.3s\n",
      "586:\tlearn: 0.3514512\ttotal: 1.85s\tremaining: 1.3s\n",
      "587:\tlearn: 0.3513713\ttotal: 1.85s\tremaining: 1.3s\n",
      "588:\tlearn: 0.3512944\ttotal: 1.85s\tremaining: 1.29s\n",
      "589:\tlearn: 0.3511648\ttotal: 1.86s\tremaining: 1.29s\n",
      "590:\tlearn: 0.3511247\ttotal: 1.86s\tremaining: 1.29s\n",
      "591:\tlearn: 0.3510488\ttotal: 1.86s\tremaining: 1.28s\n",
      "592:\tlearn: 0.3508964\ttotal: 1.86s\tremaining: 1.28s\n",
      "593:\tlearn: 0.3507754\ttotal: 1.87s\tremaining: 1.27s\n",
      "594:\tlearn: 0.3505631\ttotal: 1.87s\tremaining: 1.27s\n",
      "595:\tlearn: 0.3504567\ttotal: 1.87s\tremaining: 1.27s\n",
      "596:\tlearn: 0.3503935\ttotal: 1.87s\tremaining: 1.26s\n",
      "597:\tlearn: 0.3503638\ttotal: 1.87s\tremaining: 1.26s\n",
      "598:\tlearn: 0.3503152\ttotal: 1.88s\tremaining: 1.25s\n",
      "599:\tlearn: 0.3502545\ttotal: 1.88s\tremaining: 1.25s\n",
      "600:\tlearn: 0.3501172\ttotal: 1.88s\tremaining: 1.25s\n",
      "601:\tlearn: 0.3500050\ttotal: 1.88s\tremaining: 1.24s\n",
      "602:\tlearn: 0.3499102\ttotal: 1.88s\tremaining: 1.24s\n",
      "603:\tlearn: 0.3497622\ttotal: 1.89s\tremaining: 1.24s\n",
      "604:\tlearn: 0.3497068\ttotal: 1.89s\tremaining: 1.23s\n",
      "605:\tlearn: 0.3495752\ttotal: 1.89s\tremaining: 1.23s\n",
      "606:\tlearn: 0.3494889\ttotal: 1.89s\tremaining: 1.22s\n",
      "607:\tlearn: 0.3493889\ttotal: 1.89s\tremaining: 1.22s\n",
      "608:\tlearn: 0.3493164\ttotal: 1.9s\tremaining: 1.22s\n",
      "609:\tlearn: 0.3491742\ttotal: 1.9s\tremaining: 1.21s\n",
      "610:\tlearn: 0.3490399\ttotal: 1.9s\tremaining: 1.21s\n",
      "611:\tlearn: 0.3489572\ttotal: 1.9s\tremaining: 1.21s\n",
      "612:\tlearn: 0.3489101\ttotal: 1.91s\tremaining: 1.2s\n",
      "613:\tlearn: 0.3488545\ttotal: 1.91s\tremaining: 1.2s\n",
      "614:\tlearn: 0.3487652\ttotal: 1.91s\tremaining: 1.2s\n",
      "615:\tlearn: 0.3486843\ttotal: 1.91s\tremaining: 1.19s\n",
      "616:\tlearn: 0.3485638\ttotal: 1.91s\tremaining: 1.19s\n",
      "617:\tlearn: 0.3484779\ttotal: 1.92s\tremaining: 1.18s\n",
      "618:\tlearn: 0.3484062\ttotal: 1.92s\tremaining: 1.18s\n",
      "619:\tlearn: 0.3483075\ttotal: 1.92s\tremaining: 1.18s\n",
      "620:\tlearn: 0.3482328\ttotal: 1.92s\tremaining: 1.17s\n",
      "621:\tlearn: 0.3481184\ttotal: 1.92s\tremaining: 1.17s\n",
      "622:\tlearn: 0.3479966\ttotal: 1.93s\tremaining: 1.17s\n",
      "623:\tlearn: 0.3478658\ttotal: 1.93s\tremaining: 1.16s\n",
      "624:\tlearn: 0.3477841\ttotal: 1.93s\tremaining: 1.16s\n",
      "625:\tlearn: 0.3476931\ttotal: 1.93s\tremaining: 1.15s\n",
      "626:\tlearn: 0.3476036\ttotal: 1.93s\tremaining: 1.15s\n",
      "627:\tlearn: 0.3474691\ttotal: 1.94s\tremaining: 1.15s\n",
      "628:\tlearn: 0.3473587\ttotal: 1.94s\tremaining: 1.14s\n",
      "629:\tlearn: 0.3472748\ttotal: 1.94s\tremaining: 1.14s\n",
      "630:\tlearn: 0.3471811\ttotal: 1.94s\tremaining: 1.14s\n",
      "631:\tlearn: 0.3470532\ttotal: 1.95s\tremaining: 1.13s\n",
      "632:\tlearn: 0.3469721\ttotal: 1.95s\tremaining: 1.13s\n",
      "633:\tlearn: 0.3468639\ttotal: 1.95s\tremaining: 1.13s\n",
      "634:\tlearn: 0.3467707\ttotal: 1.95s\tremaining: 1.12s\n",
      "635:\tlearn: 0.3466684\ttotal: 1.96s\tremaining: 1.12s\n",
      "636:\tlearn: 0.3466377\ttotal: 1.96s\tremaining: 1.11s\n",
      "637:\tlearn: 0.3465648\ttotal: 1.96s\tremaining: 1.11s\n",
      "638:\tlearn: 0.3464712\ttotal: 1.96s\tremaining: 1.11s\n",
      "639:\tlearn: 0.3463419\ttotal: 1.96s\tremaining: 1.1s\n",
      "640:\tlearn: 0.3462479\ttotal: 1.97s\tremaining: 1.1s\n",
      "641:\tlearn: 0.3461622\ttotal: 1.97s\tremaining: 1.1s\n",
      "642:\tlearn: 0.3460319\ttotal: 1.97s\tremaining: 1.09s\n",
      "643:\tlearn: 0.3459970\ttotal: 1.97s\tremaining: 1.09s\n",
      "644:\tlearn: 0.3459461\ttotal: 1.97s\tremaining: 1.08s\n",
      "645:\tlearn: 0.3458752\ttotal: 1.97s\tremaining: 1.08s\n",
      "646:\tlearn: 0.3457846\ttotal: 1.98s\tremaining: 1.08s\n",
      "647:\tlearn: 0.3456951\ttotal: 1.98s\tremaining: 1.07s\n",
      "648:\tlearn: 0.3455513\ttotal: 1.98s\tremaining: 1.07s\n",
      "649:\tlearn: 0.3455288\ttotal: 1.98s\tremaining: 1.07s\n",
      "650:\tlearn: 0.3454029\ttotal: 1.98s\tremaining: 1.06s\n",
      "651:\tlearn: 0.3452692\ttotal: 1.99s\tremaining: 1.06s\n",
      "652:\tlearn: 0.3452033\ttotal: 1.99s\tremaining: 1.06s\n",
      "653:\tlearn: 0.3450900\ttotal: 1.99s\tremaining: 1.05s\n",
      "654:\tlearn: 0.3449734\ttotal: 1.99s\tremaining: 1.05s\n",
      "655:\tlearn: 0.3448769\ttotal: 1.99s\tremaining: 1.04s\n",
      "656:\tlearn: 0.3448186\ttotal: 2s\tremaining: 1.04s\n",
      "657:\tlearn: 0.3446974\ttotal: 2s\tremaining: 1.04s\n",
      "658:\tlearn: 0.3446064\ttotal: 2s\tremaining: 1.03s\n",
      "659:\tlearn: 0.3444861\ttotal: 2s\tremaining: 1.03s\n",
      "660:\tlearn: 0.3443864\ttotal: 2s\tremaining: 1.03s\n",
      "661:\tlearn: 0.3442919\ttotal: 2.01s\tremaining: 1.02s\n",
      "662:\tlearn: 0.3441903\ttotal: 2.01s\tremaining: 1.02s\n",
      "663:\tlearn: 0.3440543\ttotal: 2.01s\tremaining: 1.02s\n",
      "664:\tlearn: 0.3439456\ttotal: 2.01s\tremaining: 1.01s\n",
      "665:\tlearn: 0.3438775\ttotal: 2.02s\tremaining: 1.01s\n",
      "666:\tlearn: 0.3437522\ttotal: 2.02s\tremaining: 1.01s\n",
      "667:\tlearn: 0.3436250\ttotal: 2.02s\tremaining: 1s\n",
      "668:\tlearn: 0.3435054\ttotal: 2.02s\tremaining: 1s\n",
      "669:\tlearn: 0.3434518\ttotal: 2.02s\tremaining: 997ms\n",
      "670:\tlearn: 0.3433625\ttotal: 2.02s\tremaining: 993ms\n",
      "671:\tlearn: 0.3432597\ttotal: 2.03s\tremaining: 990ms\n",
      "672:\tlearn: 0.3432116\ttotal: 2.03s\tremaining: 986ms\n",
      "673:\tlearn: 0.3431303\ttotal: 2.03s\tremaining: 982ms\n",
      "674:\tlearn: 0.3430491\ttotal: 2.03s\tremaining: 979ms\n",
      "675:\tlearn: 0.3429815\ttotal: 2.03s\tremaining: 975ms\n",
      "676:\tlearn: 0.3428637\ttotal: 2.04s\tremaining: 972ms\n",
      "677:\tlearn: 0.3427014\ttotal: 2.04s\tremaining: 968ms\n",
      "678:\tlearn: 0.3426454\ttotal: 2.04s\tremaining: 965ms\n",
      "679:\tlearn: 0.3425916\ttotal: 2.04s\tremaining: 962ms\n",
      "680:\tlearn: 0.3425119\ttotal: 2.04s\tremaining: 958ms\n",
      "681:\tlearn: 0.3423375\ttotal: 2.05s\tremaining: 955ms\n",
      "682:\tlearn: 0.3422425\ttotal: 2.05s\tremaining: 952ms\n",
      "683:\tlearn: 0.3421462\ttotal: 2.05s\tremaining: 948ms\n",
      "684:\tlearn: 0.3420142\ttotal: 2.05s\tremaining: 945ms\n",
      "685:\tlearn: 0.3418888\ttotal: 2.06s\tremaining: 941ms\n",
      "686:\tlearn: 0.3418244\ttotal: 2.06s\tremaining: 938ms\n",
      "687:\tlearn: 0.3417328\ttotal: 2.06s\tremaining: 934ms\n",
      "688:\tlearn: 0.3415916\ttotal: 2.06s\tremaining: 931ms\n",
      "689:\tlearn: 0.3414702\ttotal: 2.06s\tremaining: 927ms\n",
      "690:\tlearn: 0.3413745\ttotal: 2.06s\tremaining: 924ms\n",
      "691:\tlearn: 0.3412827\ttotal: 2.07s\tremaining: 921ms\n",
      "692:\tlearn: 0.3412026\ttotal: 2.07s\tremaining: 917ms\n",
      "693:\tlearn: 0.3411257\ttotal: 2.07s\tremaining: 914ms\n",
      "694:\tlearn: 0.3410469\ttotal: 2.07s\tremaining: 910ms\n",
      "695:\tlearn: 0.3409517\ttotal: 2.08s\tremaining: 907ms\n",
      "696:\tlearn: 0.3408319\ttotal: 2.08s\tremaining: 903ms\n",
      "697:\tlearn: 0.3407131\ttotal: 2.08s\tremaining: 900ms\n",
      "698:\tlearn: 0.3406270\ttotal: 2.08s\tremaining: 896ms\n",
      "699:\tlearn: 0.3405982\ttotal: 2.08s\tremaining: 893ms\n",
      "700:\tlearn: 0.3404715\ttotal: 2.09s\tremaining: 890ms\n",
      "701:\tlearn: 0.3403332\ttotal: 2.09s\tremaining: 887ms\n",
      "702:\tlearn: 0.3401992\ttotal: 2.09s\tremaining: 884ms\n",
      "703:\tlearn: 0.3400765\ttotal: 2.09s\tremaining: 880ms\n",
      "704:\tlearn: 0.3400532\ttotal: 2.1s\tremaining: 877ms\n",
      "705:\tlearn: 0.3399325\ttotal: 2.1s\tremaining: 873ms\n",
      "706:\tlearn: 0.3398249\ttotal: 2.1s\tremaining: 870ms\n",
      "707:\tlearn: 0.3397212\ttotal: 2.1s\tremaining: 867ms\n",
      "708:\tlearn: 0.3396336\ttotal: 2.1s\tremaining: 864ms\n",
      "709:\tlearn: 0.3395726\ttotal: 2.11s\tremaining: 861ms\n",
      "710:\tlearn: 0.3395465\ttotal: 2.11s\tremaining: 857ms\n",
      "711:\tlearn: 0.3394433\ttotal: 2.11s\tremaining: 854ms\n",
      "712:\tlearn: 0.3393497\ttotal: 2.11s\tremaining: 851ms\n",
      "713:\tlearn: 0.3393017\ttotal: 2.12s\tremaining: 848ms\n",
      "714:\tlearn: 0.3391802\ttotal: 2.12s\tremaining: 845ms\n",
      "715:\tlearn: 0.3391487\ttotal: 2.12s\tremaining: 842ms\n",
      "716:\tlearn: 0.3390735\ttotal: 2.12s\tremaining: 839ms\n",
      "717:\tlearn: 0.3389916\ttotal: 2.13s\tremaining: 835ms\n",
      "718:\tlearn: 0.3388696\ttotal: 2.13s\tremaining: 832ms\n",
      "719:\tlearn: 0.3388213\ttotal: 2.13s\tremaining: 829ms\n",
      "720:\tlearn: 0.3387627\ttotal: 2.13s\tremaining: 825ms\n",
      "721:\tlearn: 0.3386781\ttotal: 2.13s\tremaining: 822ms\n",
      "722:\tlearn: 0.3385950\ttotal: 2.14s\tremaining: 819ms\n",
      "723:\tlearn: 0.3385337\ttotal: 2.14s\tremaining: 816ms\n",
      "724:\tlearn: 0.3384577\ttotal: 2.14s\tremaining: 812ms\n",
      "725:\tlearn: 0.3384076\ttotal: 2.14s\tremaining: 809ms\n",
      "726:\tlearn: 0.3383073\ttotal: 2.15s\tremaining: 806ms\n",
      "727:\tlearn: 0.3381958\ttotal: 2.15s\tremaining: 803ms\n",
      "728:\tlearn: 0.3381170\ttotal: 2.15s\tremaining: 799ms\n",
      "729:\tlearn: 0.3380608\ttotal: 2.15s\tremaining: 796ms\n",
      "730:\tlearn: 0.3379469\ttotal: 2.15s\tremaining: 792ms\n",
      "731:\tlearn: 0.3378650\ttotal: 2.15s\tremaining: 789ms\n",
      "732:\tlearn: 0.3378063\ttotal: 2.16s\tremaining: 786ms\n",
      "733:\tlearn: 0.3376786\ttotal: 2.16s\tremaining: 782ms\n",
      "734:\tlearn: 0.3375696\ttotal: 2.16s\tremaining: 779ms\n",
      "735:\tlearn: 0.3374807\ttotal: 2.16s\tremaining: 776ms\n",
      "736:\tlearn: 0.3374257\ttotal: 2.17s\tremaining: 773ms\n",
      "737:\tlearn: 0.3373495\ttotal: 2.17s\tremaining: 769ms\n",
      "738:\tlearn: 0.3372046\ttotal: 2.17s\tremaining: 766ms\n",
      "739:\tlearn: 0.3371991\ttotal: 2.17s\tremaining: 763ms\n",
      "740:\tlearn: 0.3371517\ttotal: 2.17s\tremaining: 759ms\n",
      "741:\tlearn: 0.3370298\ttotal: 2.17s\tremaining: 756ms\n",
      "742:\tlearn: 0.3369464\ttotal: 2.18s\tremaining: 753ms\n",
      "743:\tlearn: 0.3368334\ttotal: 2.18s\tremaining: 750ms\n",
      "744:\tlearn: 0.3367509\ttotal: 2.18s\tremaining: 746ms\n",
      "745:\tlearn: 0.3366556\ttotal: 2.18s\tremaining: 743ms\n",
      "746:\tlearn: 0.3365419\ttotal: 2.18s\tremaining: 740ms\n",
      "747:\tlearn: 0.3365097\ttotal: 2.19s\tremaining: 737ms\n",
      "748:\tlearn: 0.3364288\ttotal: 2.19s\tremaining: 733ms\n",
      "749:\tlearn: 0.3363160\ttotal: 2.19s\tremaining: 730ms\n",
      "750:\tlearn: 0.3362130\ttotal: 2.19s\tremaining: 727ms\n",
      "751:\tlearn: 0.3361637\ttotal: 2.19s\tremaining: 724ms\n",
      "752:\tlearn: 0.3361202\ttotal: 2.2s\tremaining: 721ms\n",
      "753:\tlearn: 0.3360512\ttotal: 2.2s\tremaining: 717ms\n",
      "754:\tlearn: 0.3359052\ttotal: 2.2s\tremaining: 714ms\n",
      "755:\tlearn: 0.3358060\ttotal: 2.2s\tremaining: 711ms\n",
      "756:\tlearn: 0.3357656\ttotal: 2.2s\tremaining: 707ms\n",
      "757:\tlearn: 0.3356767\ttotal: 2.21s\tremaining: 704ms\n",
      "758:\tlearn: 0.3355758\ttotal: 2.21s\tremaining: 701ms\n",
      "759:\tlearn: 0.3354685\ttotal: 2.21s\tremaining: 698ms\n",
      "760:\tlearn: 0.3353973\ttotal: 2.21s\tremaining: 695ms\n",
      "761:\tlearn: 0.3353568\ttotal: 2.21s\tremaining: 691ms\n",
      "762:\tlearn: 0.3352735\ttotal: 2.21s\tremaining: 688ms\n",
      "763:\tlearn: 0.3351351\ttotal: 2.22s\tremaining: 685ms\n",
      "764:\tlearn: 0.3350585\ttotal: 2.22s\tremaining: 682ms\n",
      "765:\tlearn: 0.3349547\ttotal: 2.22s\tremaining: 678ms\n",
      "766:\tlearn: 0.3348864\ttotal: 2.22s\tremaining: 675ms\n",
      "767:\tlearn: 0.3348182\ttotal: 2.22s\tremaining: 672ms\n",
      "768:\tlearn: 0.3347071\ttotal: 2.23s\tremaining: 669ms\n",
      "769:\tlearn: 0.3346275\ttotal: 2.23s\tremaining: 666ms\n",
      "770:\tlearn: 0.3345782\ttotal: 2.23s\tremaining: 663ms\n",
      "771:\tlearn: 0.3345252\ttotal: 2.23s\tremaining: 660ms\n",
      "772:\tlearn: 0.3344086\ttotal: 2.24s\tremaining: 657ms\n",
      "773:\tlearn: 0.3343150\ttotal: 2.24s\tremaining: 654ms\n",
      "774:\tlearn: 0.3342413\ttotal: 2.24s\tremaining: 651ms\n",
      "775:\tlearn: 0.3342140\ttotal: 2.24s\tremaining: 648ms\n",
      "776:\tlearn: 0.3341630\ttotal: 2.25s\tremaining: 645ms\n",
      "777:\tlearn: 0.3340602\ttotal: 2.25s\tremaining: 642ms\n",
      "778:\tlearn: 0.3339901\ttotal: 2.25s\tremaining: 638ms\n",
      "779:\tlearn: 0.3339133\ttotal: 2.25s\tremaining: 635ms\n",
      "780:\tlearn: 0.3337560\ttotal: 2.25s\tremaining: 632ms\n",
      "781:\tlearn: 0.3337064\ttotal: 2.26s\tremaining: 629ms\n",
      "782:\tlearn: 0.3336210\ttotal: 2.26s\tremaining: 626ms\n",
      "783:\tlearn: 0.3335419\ttotal: 2.26s\tremaining: 623ms\n",
      "784:\tlearn: 0.3334376\ttotal: 2.26s\tremaining: 620ms\n",
      "785:\tlearn: 0.3333408\ttotal: 2.26s\tremaining: 616ms\n",
      "786:\tlearn: 0.3333121\ttotal: 2.27s\tremaining: 613ms\n",
      "787:\tlearn: 0.3332357\ttotal: 2.27s\tremaining: 610ms\n",
      "788:\tlearn: 0.3331428\ttotal: 2.27s\tremaining: 607ms\n",
      "789:\tlearn: 0.3330537\ttotal: 2.27s\tremaining: 604ms\n",
      "790:\tlearn: 0.3329829\ttotal: 2.27s\tremaining: 601ms\n",
      "791:\tlearn: 0.3329210\ttotal: 2.28s\tremaining: 598ms\n",
      "792:\tlearn: 0.3328318\ttotal: 2.28s\tremaining: 595ms\n",
      "793:\tlearn: 0.3327860\ttotal: 2.28s\tremaining: 592ms\n",
      "794:\tlearn: 0.3327252\ttotal: 2.28s\tremaining: 589ms\n",
      "795:\tlearn: 0.3326337\ttotal: 2.29s\tremaining: 586ms\n",
      "796:\tlearn: 0.3325265\ttotal: 2.29s\tremaining: 583ms\n",
      "797:\tlearn: 0.3324334\ttotal: 2.29s\tremaining: 580ms\n",
      "798:\tlearn: 0.3323803\ttotal: 2.29s\tremaining: 577ms\n",
      "799:\tlearn: 0.3322891\ttotal: 2.3s\tremaining: 574ms\n",
      "800:\tlearn: 0.3322096\ttotal: 2.3s\tremaining: 571ms\n",
      "801:\tlearn: 0.3321241\ttotal: 2.3s\tremaining: 568ms\n",
      "802:\tlearn: 0.3320595\ttotal: 2.3s\tremaining: 565ms\n",
      "803:\tlearn: 0.3319763\ttotal: 2.31s\tremaining: 562ms\n",
      "804:\tlearn: 0.3319484\ttotal: 2.31s\tremaining: 559ms\n",
      "805:\tlearn: 0.3318624\ttotal: 2.31s\tremaining: 556ms\n",
      "806:\tlearn: 0.3318378\ttotal: 2.31s\tremaining: 553ms\n",
      "807:\tlearn: 0.3317850\ttotal: 2.31s\tremaining: 550ms\n",
      "808:\tlearn: 0.3317426\ttotal: 2.32s\tremaining: 547ms\n",
      "809:\tlearn: 0.3316457\ttotal: 2.32s\tremaining: 545ms\n",
      "810:\tlearn: 0.3315869\ttotal: 2.32s\tremaining: 541ms\n",
      "811:\tlearn: 0.3315056\ttotal: 2.33s\tremaining: 538ms\n",
      "812:\tlearn: 0.3313857\ttotal: 2.33s\tremaining: 535ms\n",
      "813:\tlearn: 0.3312979\ttotal: 2.33s\tremaining: 532ms\n",
      "814:\tlearn: 0.3312575\ttotal: 2.33s\tremaining: 529ms\n",
      "815:\tlearn: 0.3311753\ttotal: 2.33s\tremaining: 526ms\n",
      "816:\tlearn: 0.3311085\ttotal: 2.33s\tremaining: 523ms\n",
      "817:\tlearn: 0.3310409\ttotal: 2.34s\tremaining: 520ms\n",
      "818:\tlearn: 0.3309907\ttotal: 2.34s\tremaining: 517ms\n",
      "819:\tlearn: 0.3309704\ttotal: 2.34s\tremaining: 514ms\n",
      "820:\tlearn: 0.3309317\ttotal: 2.34s\tremaining: 511ms\n",
      "821:\tlearn: 0.3308322\ttotal: 2.34s\tremaining: 508ms\n",
      "822:\tlearn: 0.3307405\ttotal: 2.35s\tremaining: 505ms\n",
      "823:\tlearn: 0.3306952\ttotal: 2.35s\tremaining: 502ms\n",
      "824:\tlearn: 0.3305673\ttotal: 2.35s\tremaining: 499ms\n",
      "825:\tlearn: 0.3304786\ttotal: 2.35s\tremaining: 496ms\n",
      "826:\tlearn: 0.3303526\ttotal: 2.35s\tremaining: 493ms\n",
      "827:\tlearn: 0.3302754\ttotal: 2.36s\tremaining: 490ms\n",
      "828:\tlearn: 0.3302146\ttotal: 2.36s\tremaining: 486ms\n",
      "829:\tlearn: 0.3301373\ttotal: 2.36s\tremaining: 483ms\n",
      "830:\tlearn: 0.3300543\ttotal: 2.36s\tremaining: 480ms\n",
      "831:\tlearn: 0.3299802\ttotal: 2.36s\tremaining: 478ms\n",
      "832:\tlearn: 0.3298882\ttotal: 2.37s\tremaining: 475ms\n",
      "833:\tlearn: 0.3297958\ttotal: 2.37s\tremaining: 472ms\n",
      "834:\tlearn: 0.3297246\ttotal: 2.37s\tremaining: 469ms\n",
      "835:\tlearn: 0.3296164\ttotal: 2.37s\tremaining: 466ms\n",
      "836:\tlearn: 0.3294901\ttotal: 2.38s\tremaining: 463ms\n",
      "837:\tlearn: 0.3294082\ttotal: 2.38s\tremaining: 460ms\n",
      "838:\tlearn: 0.3293287\ttotal: 2.38s\tremaining: 457ms\n",
      "839:\tlearn: 0.3292540\ttotal: 2.38s\tremaining: 454ms\n",
      "840:\tlearn: 0.3290801\ttotal: 2.38s\tremaining: 451ms\n",
      "841:\tlearn: 0.3289960\ttotal: 2.38s\tremaining: 448ms\n",
      "842:\tlearn: 0.3288899\ttotal: 2.39s\tremaining: 445ms\n",
      "843:\tlearn: 0.3288050\ttotal: 2.39s\tremaining: 442ms\n",
      "844:\tlearn: 0.3287068\ttotal: 2.39s\tremaining: 439ms\n",
      "845:\tlearn: 0.3286065\ttotal: 2.39s\tremaining: 436ms\n",
      "846:\tlearn: 0.3284977\ttotal: 2.4s\tremaining: 433ms\n",
      "847:\tlearn: 0.3284505\ttotal: 2.4s\tremaining: 430ms\n",
      "848:\tlearn: 0.3283350\ttotal: 2.4s\tremaining: 427ms\n",
      "849:\tlearn: 0.3282650\ttotal: 2.4s\tremaining: 424ms\n",
      "850:\tlearn: 0.3281772\ttotal: 2.4s\tremaining: 421ms\n",
      "851:\tlearn: 0.3281241\ttotal: 2.4s\tremaining: 418ms\n",
      "852:\tlearn: 0.3280294\ttotal: 2.41s\tremaining: 415ms\n",
      "853:\tlearn: 0.3279705\ttotal: 2.41s\tremaining: 412ms\n",
      "854:\tlearn: 0.3278910\ttotal: 2.41s\tremaining: 409ms\n",
      "855:\tlearn: 0.3278658\ttotal: 2.41s\tremaining: 406ms\n",
      "856:\tlearn: 0.3278186\ttotal: 2.42s\tremaining: 403ms\n",
      "857:\tlearn: 0.3277739\ttotal: 2.42s\tremaining: 400ms\n",
      "858:\tlearn: 0.3277264\ttotal: 2.42s\tremaining: 397ms\n",
      "859:\tlearn: 0.3276406\ttotal: 2.42s\tremaining: 394ms\n",
      "860:\tlearn: 0.3275974\ttotal: 2.42s\tremaining: 391ms\n",
      "861:\tlearn: 0.3275092\ttotal: 2.43s\tremaining: 388ms\n",
      "862:\tlearn: 0.3273973\ttotal: 2.43s\tremaining: 386ms\n",
      "863:\tlearn: 0.3273791\ttotal: 2.43s\tremaining: 383ms\n",
      "864:\tlearn: 0.3272615\ttotal: 2.43s\tremaining: 380ms\n",
      "865:\tlearn: 0.3271870\ttotal: 2.43s\tremaining: 377ms\n",
      "866:\tlearn: 0.3271218\ttotal: 2.44s\tremaining: 374ms\n",
      "867:\tlearn: 0.3270517\ttotal: 2.44s\tremaining: 371ms\n",
      "868:\tlearn: 0.3269624\ttotal: 2.44s\tremaining: 368ms\n",
      "869:\tlearn: 0.3269170\ttotal: 2.44s\tremaining: 365ms\n",
      "870:\tlearn: 0.3268431\ttotal: 2.44s\tremaining: 362ms\n",
      "871:\tlearn: 0.3267058\ttotal: 2.45s\tremaining: 359ms\n",
      "872:\tlearn: 0.3265930\ttotal: 2.45s\tremaining: 356ms\n",
      "873:\tlearn: 0.3265490\ttotal: 2.45s\tremaining: 353ms\n",
      "874:\tlearn: 0.3264576\ttotal: 2.45s\tremaining: 350ms\n",
      "875:\tlearn: 0.3263887\ttotal: 2.45s\tremaining: 347ms\n",
      "876:\tlearn: 0.3262568\ttotal: 2.46s\tremaining: 345ms\n",
      "877:\tlearn: 0.3262240\ttotal: 2.46s\tremaining: 342ms\n",
      "878:\tlearn: 0.3261800\ttotal: 2.46s\tremaining: 339ms\n",
      "879:\tlearn: 0.3260970\ttotal: 2.46s\tremaining: 336ms\n",
      "880:\tlearn: 0.3259878\ttotal: 2.47s\tremaining: 333ms\n",
      "881:\tlearn: 0.3258863\ttotal: 2.47s\tremaining: 330ms\n",
      "882:\tlearn: 0.3258109\ttotal: 2.47s\tremaining: 327ms\n",
      "883:\tlearn: 0.3256852\ttotal: 2.47s\tremaining: 325ms\n",
      "884:\tlearn: 0.3256021\ttotal: 2.48s\tremaining: 322ms\n",
      "885:\tlearn: 0.3255106\ttotal: 2.48s\tremaining: 319ms\n",
      "886:\tlearn: 0.3254434\ttotal: 2.48s\tremaining: 316ms\n",
      "887:\tlearn: 0.3253562\ttotal: 2.48s\tremaining: 313ms\n",
      "888:\tlearn: 0.3252323\ttotal: 2.48s\tremaining: 310ms\n",
      "889:\tlearn: 0.3251757\ttotal: 2.49s\tremaining: 307ms\n",
      "890:\tlearn: 0.3251016\ttotal: 2.49s\tremaining: 305ms\n",
      "891:\tlearn: 0.3250136\ttotal: 2.49s\tremaining: 302ms\n",
      "892:\tlearn: 0.3249642\ttotal: 2.49s\tremaining: 299ms\n",
      "893:\tlearn: 0.3248969\ttotal: 2.5s\tremaining: 296ms\n",
      "894:\tlearn: 0.3247655\ttotal: 2.5s\tremaining: 293ms\n",
      "895:\tlearn: 0.3247261\ttotal: 2.5s\tremaining: 290ms\n",
      "896:\tlearn: 0.3246481\ttotal: 2.5s\tremaining: 287ms\n",
      "897:\tlearn: 0.3245462\ttotal: 2.5s\tremaining: 284ms\n",
      "898:\tlearn: 0.3244304\ttotal: 2.51s\tremaining: 282ms\n",
      "899:\tlearn: 0.3243433\ttotal: 2.51s\tremaining: 279ms\n",
      "900:\tlearn: 0.3242922\ttotal: 2.51s\tremaining: 276ms\n",
      "901:\tlearn: 0.3241963\ttotal: 2.51s\tremaining: 273ms\n",
      "902:\tlearn: 0.3241202\ttotal: 2.51s\tremaining: 270ms\n",
      "903:\tlearn: 0.3240693\ttotal: 2.52s\tremaining: 267ms\n",
      "904:\tlearn: 0.3239913\ttotal: 2.52s\tremaining: 264ms\n",
      "905:\tlearn: 0.3239719\ttotal: 2.52s\tremaining: 261ms\n",
      "906:\tlearn: 0.3239362\ttotal: 2.52s\tremaining: 259ms\n",
      "907:\tlearn: 0.3238367\ttotal: 2.52s\tremaining: 256ms\n",
      "908:\tlearn: 0.3237862\ttotal: 2.53s\tremaining: 253ms\n",
      "909:\tlearn: 0.3236894\ttotal: 2.53s\tremaining: 250ms\n",
      "910:\tlearn: 0.3235875\ttotal: 2.53s\tremaining: 247ms\n",
      "911:\tlearn: 0.3234948\ttotal: 2.53s\tremaining: 244ms\n",
      "912:\tlearn: 0.3234174\ttotal: 2.53s\tremaining: 241ms\n",
      "913:\tlearn: 0.3233370\ttotal: 2.54s\tremaining: 239ms\n",
      "914:\tlearn: 0.3232458\ttotal: 2.54s\tremaining: 236ms\n",
      "915:\tlearn: 0.3231864\ttotal: 2.54s\tremaining: 233ms\n",
      "916:\tlearn: 0.3231236\ttotal: 2.54s\tremaining: 230ms\n",
      "917:\tlearn: 0.3230492\ttotal: 2.54s\tremaining: 227ms\n",
      "918:\tlearn: 0.3229986\ttotal: 2.55s\tremaining: 224ms\n",
      "919:\tlearn: 0.3228379\ttotal: 2.55s\tremaining: 222ms\n",
      "920:\tlearn: 0.3227428\ttotal: 2.55s\tremaining: 219ms\n",
      "921:\tlearn: 0.3226238\ttotal: 2.55s\tremaining: 216ms\n",
      "922:\tlearn: 0.3225481\ttotal: 2.55s\tremaining: 213ms\n",
      "923:\tlearn: 0.3224894\ttotal: 2.56s\tremaining: 210ms\n",
      "924:\tlearn: 0.3224338\ttotal: 2.56s\tremaining: 207ms\n",
      "925:\tlearn: 0.3223820\ttotal: 2.56s\tremaining: 205ms\n",
      "926:\tlearn: 0.3222722\ttotal: 2.56s\tremaining: 202ms\n",
      "927:\tlearn: 0.3221972\ttotal: 2.56s\tremaining: 199ms\n",
      "928:\tlearn: 0.3221482\ttotal: 2.56s\tremaining: 196ms\n",
      "929:\tlearn: 0.3220991\ttotal: 2.57s\tremaining: 193ms\n",
      "930:\tlearn: 0.3220595\ttotal: 2.57s\tremaining: 190ms\n",
      "931:\tlearn: 0.3219591\ttotal: 2.57s\tremaining: 188ms\n",
      "932:\tlearn: 0.3218835\ttotal: 2.57s\tremaining: 185ms\n",
      "933:\tlearn: 0.3218208\ttotal: 2.58s\tremaining: 182ms\n",
      "934:\tlearn: 0.3217304\ttotal: 2.58s\tremaining: 179ms\n",
      "935:\tlearn: 0.3216119\ttotal: 2.58s\tremaining: 176ms\n",
      "936:\tlearn: 0.3214964\ttotal: 2.58s\tremaining: 174ms\n",
      "937:\tlearn: 0.3214261\ttotal: 2.58s\tremaining: 171ms\n",
      "938:\tlearn: 0.3213306\ttotal: 2.58s\tremaining: 168ms\n",
      "939:\tlearn: 0.3212203\ttotal: 2.59s\tremaining: 165ms\n",
      "940:\tlearn: 0.3211612\ttotal: 2.59s\tremaining: 162ms\n",
      "941:\tlearn: 0.3211196\ttotal: 2.59s\tremaining: 159ms\n",
      "942:\tlearn: 0.3210570\ttotal: 2.59s\tremaining: 157ms\n",
      "943:\tlearn: 0.3210171\ttotal: 2.59s\tremaining: 154ms\n",
      "944:\tlearn: 0.3209294\ttotal: 2.6s\tremaining: 151ms\n",
      "945:\tlearn: 0.3208403\ttotal: 2.6s\tremaining: 148ms\n",
      "946:\tlearn: 0.3208236\ttotal: 2.6s\tremaining: 146ms\n",
      "947:\tlearn: 0.3207754\ttotal: 2.6s\tremaining: 143ms\n",
      "948:\tlearn: 0.3206861\ttotal: 2.6s\tremaining: 140ms\n",
      "949:\tlearn: 0.3206497\ttotal: 2.61s\tremaining: 137ms\n",
      "950:\tlearn: 0.3205729\ttotal: 2.61s\tremaining: 134ms\n",
      "951:\tlearn: 0.3204584\ttotal: 2.61s\tremaining: 132ms\n",
      "952:\tlearn: 0.3203849\ttotal: 2.61s\tremaining: 129ms\n",
      "953:\tlearn: 0.3203215\ttotal: 2.61s\tremaining: 126ms\n",
      "954:\tlearn: 0.3202693\ttotal: 2.62s\tremaining: 123ms\n",
      "955:\tlearn: 0.3201843\ttotal: 2.62s\tremaining: 121ms\n",
      "956:\tlearn: 0.3200639\ttotal: 2.62s\tremaining: 118ms\n",
      "957:\tlearn: 0.3199914\ttotal: 2.62s\tremaining: 115ms\n",
      "958:\tlearn: 0.3199250\ttotal: 2.62s\tremaining: 112ms\n",
      "959:\tlearn: 0.3198633\ttotal: 2.63s\tremaining: 109ms\n",
      "960:\tlearn: 0.3197840\ttotal: 2.63s\tremaining: 107ms\n",
      "961:\tlearn: 0.3197559\ttotal: 2.63s\tremaining: 104ms\n",
      "962:\tlearn: 0.3196835\ttotal: 2.63s\tremaining: 101ms\n",
      "963:\tlearn: 0.3195985\ttotal: 2.63s\tremaining: 98.4ms\n",
      "964:\tlearn: 0.3195612\ttotal: 2.63s\tremaining: 95.6ms\n",
      "965:\tlearn: 0.3194665\ttotal: 2.64s\tremaining: 92.8ms\n",
      "966:\tlearn: 0.3194165\ttotal: 2.64s\tremaining: 90.1ms\n",
      "967:\tlearn: 0.3193795\ttotal: 2.64s\tremaining: 87.3ms\n",
      "968:\tlearn: 0.3192935\ttotal: 2.64s\tremaining: 84.6ms\n",
      "969:\tlearn: 0.3192360\ttotal: 2.64s\tremaining: 81.8ms\n",
      "970:\tlearn: 0.3191610\ttotal: 2.65s\tremaining: 79.1ms\n",
      "971:\tlearn: 0.3190855\ttotal: 2.65s\tremaining: 76.3ms\n",
      "972:\tlearn: 0.3190228\ttotal: 2.65s\tremaining: 73.6ms\n",
      "973:\tlearn: 0.3189197\ttotal: 2.65s\tremaining: 70.8ms\n",
      "974:\tlearn: 0.3189022\ttotal: 2.65s\tremaining: 68.1ms\n",
      "975:\tlearn: 0.3188672\ttotal: 2.66s\tremaining: 65.3ms\n",
      "976:\tlearn: 0.3187878\ttotal: 2.66s\tremaining: 62.6ms\n",
      "977:\tlearn: 0.3186967\ttotal: 2.66s\tremaining: 59.8ms\n",
      "978:\tlearn: 0.3185826\ttotal: 2.66s\tremaining: 57.1ms\n",
      "979:\tlearn: 0.3185545\ttotal: 2.67s\tremaining: 54.4ms\n",
      "980:\tlearn: 0.3184824\ttotal: 2.67s\tremaining: 51.7ms\n",
      "981:\tlearn: 0.3184265\ttotal: 2.67s\tremaining: 48.9ms\n",
      "982:\tlearn: 0.3183704\ttotal: 2.67s\tremaining: 46.2ms\n",
      "983:\tlearn: 0.3183184\ttotal: 2.67s\tremaining: 43.5ms\n",
      "984:\tlearn: 0.3182430\ttotal: 2.67s\tremaining: 40.7ms\n",
      "985:\tlearn: 0.3181666\ttotal: 2.68s\tremaining: 38ms\n",
      "986:\tlearn: 0.3180822\ttotal: 2.68s\tremaining: 35.3ms\n",
      "987:\tlearn: 0.3179852\ttotal: 2.68s\tremaining: 32.6ms\n",
      "988:\tlearn: 0.3178993\ttotal: 2.68s\tremaining: 29.8ms\n",
      "989:\tlearn: 0.3178316\ttotal: 2.68s\tremaining: 27.1ms\n",
      "990:\tlearn: 0.3177088\ttotal: 2.69s\tremaining: 24.4ms\n",
      "991:\tlearn: 0.3176654\ttotal: 2.69s\tremaining: 21.7ms\n",
      "992:\tlearn: 0.3176176\ttotal: 2.69s\tremaining: 19ms\n",
      "993:\tlearn: 0.3175752\ttotal: 2.69s\tremaining: 16.3ms\n",
      "994:\tlearn: 0.3175131\ttotal: 2.7s\tremaining: 13.6ms\n",
      "995:\tlearn: 0.3174232\ttotal: 2.7s\tremaining: 10.8ms\n",
      "996:\tlearn: 0.3173306\ttotal: 2.7s\tremaining: 8.13ms\n",
      "997:\tlearn: 0.3172398\ttotal: 2.7s\tremaining: 5.42ms\n",
      "998:\tlearn: 0.3171348\ttotal: 2.7s\tremaining: 2.71ms\n",
      "999:\tlearn: 0.3171021\ttotal: 2.71s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fc4210776d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training catboost Classifier\n",
    "cat = CatBoostClassifier()\n",
    "cat.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on test data\n",
    "y_pred_cat = cat.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81169757489301\n",
      "Precision: 0.5966101694915255\n",
      "Recall: 0.5482866043613707\n",
      "F1-score: 0.5714285714285714\n",
      "ROC-AUC: 0.7191016740585762\n"
     ]
    }
   ],
   "source": [
    "# evaluate model accuracy,precision, recall, F1-score, and ROC-AUC.\n",
    "cat_accuracy = accuracy_score(y_test, y_pred_cat)\n",
    "cat_precision = precision_score(y_test, y_pred_cat)\n",
    "cat_recall = recall_score(y_test, y_pred_cat)\n",
    "cat_f1 = f1_score(y_test, y_pred_cat)\n",
    "cat_roc_auc = roc_auc_score(y_test, y_pred_cat)\n",
    "print('Accuracy:', cat_accuracy)\n",
    "print('Precision:', cat_precision)\n",
    "print('Recall:', cat_recall)\n",
    "print('F1-score:', cat_f1)\n",
    "print('ROC-AUC:', cat_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost model is now the best overall among tree-based models, but it's still very close to LightGBM and XGBoost. Here's the breakdown:\n",
    "\n",
    "**1.Accuracy (81.2%)** → Slightly better than LightGBM (81.0%) and XGBoost (80.7%), but still lower than Logistic Regression (82.6%).\n",
    "\n",
    "**2.Precision (59.7%)** → Best among tree-based models! Higher than LightGBM (59.3%) and XGBoost (58.1%), though still lower than Logistic Regression (64.1%).\n",
    "\n",
    "**3.Recall (54.8%)** → Same as LightGBM and slightly lower than XGBoost (57.0%).\n",
    "\n",
    "**4.F1-score (57.1%)** → Slightly better than LightGBM (56.9%) but still lower than XGBoost (57.5%) and Logistic Regression (58.9%).\n",
    "\n",
    "**5.ROC-AUC (71.9%)** → Almost identical to LightGBM (71.8%) and still lower than XGBoost (72.4%) and Logistic Regression (72.7%).\n",
    "\n",
    "#### What This Means:\n",
    "\n",
    "- CatBoost is the best overall tree-based model, slightly ahead of LightGBM and XGBoost.\n",
    "- Still, Logistic Regression is the best model so far in terms of accuracy, precision, and ROC-AUC.\n",
    "- XGBoost had the best recall (57.0%), meaning it was the best at catching churners.\n",
    "- CatBoost has the best precision (59.7%) among tree models, meaning its churn predictions are more reliable.\n",
    "\n",
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training SVM Classifier\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on test data\n",
    "y_pred_svm = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8259629101283881\n",
      "Precision: 0.672645739910314\n",
      "Recall: 0.4672897196261682\n",
      "F1-score: 0.5514705882352942\n",
      "ROC-AUC: 0.6998798274356558\n"
     ]
    }
   ],
   "source": [
    "# evaluate model accuracy,precision, recall, F1-score, and ROC-AUC.\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "svm_precision = precision_score(y_test, y_pred_svm)\n",
    "svm_recall = recall_score(y_test, y_pred_svm)\n",
    "svm_f1 = f1_score(y_test, y_pred_svm)\n",
    "svm_roc_auc = roc_auc_score(y_test, y_pred_svm)\n",
    "print('Accuracy:', svm_accuracy)\n",
    "print('Precision:', svm_precision)\n",
    "print('Recall:', svm_recall)\n",
    "print('F1-score:', svm_f1)\n",
    "print('ROC-AUC:', svm_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine (SVM) model performed differently compared to other models. Here’s how it compares:\n",
    "\n",
    "#### SVM vs. Other Models\n",
    "\n",
    "**1.Accuracy (82.6%)** → Same as Logistic Regression (Best so far!).\n",
    "\n",
    "**2.Precision (67.3%)** → Highest among all models! Better than CatBoost (59.7%) and Logistic Regression (64.1%).\n",
    "\n",
    "**3.Recall (46.7%)** → Much lower than XGBoost (57.0%) and CatBoost (54.8%), meaning it misses more real churners.\n",
    "\n",
    "**4.F1-score (55.1%)** → Worse than Logistic Regression (58.9%), meaning it doesn't balance precision and recall as well.\n",
    "\n",
    "**5.ROC-AUC (69.9%)** → Lower than Logistic Regression (72.7%) and XGBoost (72.4%), meaning it’s not as good at distinguishing churners from non-churners.\n",
    "\n",
    "#### What This Means:\n",
    "- SVM is as accurate as Logistic Regression, so it's very consistent.\n",
    "- It has the best precision (67.3%), meaning its churn predictions are the most reliable.\n",
    "- But recall is low (46.7%), meaning it misses many churners.\n",
    "- Overall, it’s good if you care more about precise predictions rather than catching every churner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
